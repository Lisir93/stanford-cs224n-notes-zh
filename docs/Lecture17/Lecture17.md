# 一 引言

![](media\1.png)

 近几年在数据集，任务，模型，度量等方面上有很大提高。只要数据集够大，模型就可以达到局部最优，我们从单个模型中学习，模型通常由随机或部分预训练开始。一般如果你拥有的输出类数量的1,000倍，效果可能达到准确率高达80％到90％，如ImageNet中，有1000个不同的计算机视觉课程，
1,000个不同的类，每个类有1,000个图像。因此，如果有大约一百万张图像，那么效果显著。但在机器翻译中，理想情况下，有几十万字，每个单词的数百万个例子，却是不适用的。

单个nlp模型集中于单个模型的度量和任务完成，不能形成典范。为了统一的模型，我们引入了NLP通用模型自然语言十项全能(decaNLP)

# 二 自然语言通用模型decaNLP

###### 任务范围

![](media\5.png)

decaNLP有十个任务：问答、机器翻译、语义角色标注、关系抽取、摘要、任务驱动多轮对话、自然语言推理、情感分析、语义解析和代词消解。同时模型研究这种模型与那些为单一任务训练而准备的模型的不同。

###### 任务概述

![](media\4.png)**问答** 

问答（QA）模型接收一个问题以及它所包含的必要的信息的上下文来输出理想的答案。数据集为斯坦福问答数据集的原始版本（SQuAD）。该上下文是从英文维基百科中摘取的段落，答案是从上下文中的一个短语。

**机器翻译**

机器翻译模型以源语言文本的形式为输入，输出为翻译好的目标语言。训练数据集为2016年为国际口语翻译研讨会(IWSLT)准备的英译德数据为，验证集和测试集为2013年和2014年的测试集作为。也可以使用额外的训练资源，比如机器翻译大赛（WMT）中的数据集。

**摘要**

摘要模型接收一个文档并输出该文档的摘要。摘要数据集为CNN/DailyMail （美国有线电视新闻网/每日邮报）语料库转换成的数据集。

**自然语言推理**

自然语言推理(NLI)模型接受两个输入句子:一个前提和一个假设。模型必须将前提和假设之间的推理关系归类为支持、中立或矛盾。我们使用的是多体裁自然语言推理语料库（MNLI），它提供来自多个领域的训练示例(转录语音、通俗小说、政府报告)和来自各个领域的测试对。

**情感分析**

情感分析模型被训练用来对输入文本表达的情感进行分类。斯坦福情感树库（SST）由一些带有相应的情绪（积极的，中立的，消极的）的影评所组成。我们使用未解析的二进制版本，以便明确对decaNLP模型的解析依赖。 

**语义角色标注**

语义角色标注（SRL）模型给出一个句子和谓语(通常是一个动词)，并且必须确定“谁对谁做了什么”、“什么时候”、“在哪里”。我们使用一个SRL数据集，该数据集将任务视为一种问答：QA-SRL。这个数据集涵盖了新闻和维基百科的领域，但是为了确保decaNLP的所有数据都可以自由下载，我们只使用了后者。 

**关系抽取**

关系抽取系统包含文本文档和要从该文本中提取的关系类型。在这种情况下，模型需要先识别实体间的语义关系，再判断是不是属于目标种类。与SRL一样，我们使用一个数据集，该数据集将关系映射到一组问题，以便关系抽取可以被视为一种问答形式：QA-ZRE。对数据集的评估是为了在新的关系上测量零样本性能——数据集是分开的使得测试时看到的关系在训练时是无法看到的。这种零样本的关系抽取，以问答为框架，可以推广到新的关系之中。

**任务驱动多轮对话**

对话状态跟踪是任务驱动多轮对话系统的关键组成部分。根据用户的话语和系统动作，对话状态跟踪器会跟踪用户为对话系统设定了哪些事先设定目标，以及用户在系统和用户交互过程中发出了哪些请求。我们使用的是英文版的WOZ餐厅预订服务，它提供了事先设定的关于食物、日期、时间、地址和其他信息的本体，可以帮助代理商为客户进行预订。

**语义解析**

SQL查询生成与语义解析相关。基于WikiSQL数据集的模型将自然语言问题转换为结构化SQL查询，以便用户可以使用自然语言与数据库交互。

**代词消解**

我们的最后一个任务是基于要求代词解析的Winograd模式：“Joan一定要感谢Susan的帮助（给予/收到）。谁给予或者收到了帮助?Joan还是Susan?”。我们从Winograd模式挑战中的示例开始，并对它们进行了修改（导致了修订的Winograd模式挑战，即MWSC），以确保答案是上下文中的单个单词，并且分数不会因上下文、问题和答案之间的措辞或不一致而增加或者减少。

**十项全能得分（decaScore）**

在decaNLP上竞争的模型是被特定任务中度量标准的附加组合来评估的。所有的度量值都在0到100之间，因此十项全能得分在10个任务中的度量值在0到1000之间。使用附加组合可以避免我们在权衡不同指标时可能产生的随意性。所有指标都不区分大小写。我们将标准化的F1（nF1）用于问答、自然语言推理、情感分析、词性标注和MWSC；平均值ROUGE-1、ROUGE-2、ROUGE-L作为摘要的评分等级；语料BLEU水平得分用于对机器翻译进行评分；联合目标跟踪精确匹配分数和基于回合的请求精确匹配得分的平均值用于对目标导向进行评分；逻辑形式精确匹配得分用于WikiSQL上的语义解析；以及语料库级F1评分等级，用于QA-ZRE的关系提取。

###### 多任务问答网络（MQAN）

![](media\7.png)

为了有效地在所有decaNLP中进行多任务处理，我们引入了MQAN，一个多任务问题回答网络，它没有任何针对特定任务的参数和模块。

MQAN采用一个问题和一个上下文背景文档，用BiLSTM（双向LSTM）编码，使用额外的共同关注层对两个序列的条件进行表示，用另两个BiLSTM压缩所有这些信息，使其能够更高层进行计算，用自我关注的方式来收集这种长距离依赖关系，然后使用两个BiLSTM对问题和背景环境的进行最终的表示。多指针生成器解码器着重于问题、上下文以及先前输出象征来决定是否从问题中复制，还是从上下文复制，或者从有限的词汇表中生成。

###### 评分与分析

![](media\9.png)

比较这些实验的结果突出了在序列到序列和通用NLP问答方法之间的多任务和单任务之间的权衡关系。从S2S到+selfSAtt提供了一种模型，该模型在混合上下文和输入的系列问题中添加了附加关注层。这大大提高了 SQuAD和WiKISQL的性能，同时也提高了QA-SRL的性能。仅此一点就足以实现WiKISQL的最新技术性能。这也表明，如果不隐性地学习如何分离它们的表示方法，而显性地去分离上下文和问题会使模型建立更丰富的表示方法。 

下一个基线使用上下文和问题作为单独的输入序列，相当于使用一个共同关注机制（+CAT）来增强S2S模型，该机制分别构建了两个序列表示。 使得每个SQuAD和QA-SRL的性能增加了 5 nF1。但遗憾的是，这种分离不能改善其他任务，并且极大地损害了MNLI和MWSC的性能。对于这两个任务，可以直接从问题中复制答案，而不是像大多数其他任务那样从上下文中复制答案。由于两个S2S基线都将问题连接到上下文，所以指针生成器机制能够直接从问题中复制。当上下文和问题被分成两个不同的输入时，模型就失去了这种能力。

为了补救这个问题，我们在前面的基线中添加了一个问题指针（+QPTR），一种在之前添加给MQAN的指针。这提高了MNLI和MWSC的性能，甚至能够比S2S基线达到更高的分数。它也改善了在SQuAD，IWSLT和 CNN/DM上的性能，该模型在WiKISQL上实现了最新的成果，是面向目标的对话数据集的第二高执行模型，并且是非显式地将问题建模为跨度提取的最高性能模型。因为当使用直接跨度监督时，我们会看到应用在通用问答中的一些局限性。

在多任务设置中，我们看到了类似的结果，但我们还注意到一些额外的显著特性。在QA-ZRE中，零样本关系提取，性能比最高的单任务模型提高11个点，这支持了多任务学习即使在零样本情况下也能得到更好的泛化的假设。在需要大量使用S2S基线的指针生成器解码器的生成器部分的任务上，性能下降了50%以上，直到问题指针再次添加到模型中。我们认为这在多任务设置中尤为重要。

原因有二：首先，问题指针除了在一个共同参与的上下文语境环境之外，还有一个共同参与的问题。这种分离允许有关问题的关键信息直接流入解码器，而不是通过共同参与的上下文。其次，通过更直接地访问这个问题，模型能够更有效地决定何时生成输出令牌比直接复制更合适。

使用这种反课程训练策略，最初只针对问答进行训练，在decaNLP上的性能也进一步有所提高。

###### 预训练MQAN优于随机初始化

![](media\10.png)

考虑到我们的模型是在丰富和多样的数据上进行训练的，它构建了强大的中间表示方法，从而实现了迁移学习。相对于一个随机初始化的模型，我们的模型在decaNLP上进行了预先训练，使得在几个新任务上更快的收敛并且也提高了分数。我们在上图中给出了两个这样的任务：命名实体识别和英文到捷克语的翻译。 我们的模型也具有领域适应的零样本能力。

我们的模型在decaNLP上接受过训练，在没有看过训练数据的情况下，我们将SNLI数据集调整到62%的精确匹配分数。因为decaNLP包含SST，它也可以在其他二进制情感分析任务中执行得很好。在亚马逊和Yelp的评论中，MQAN在decaNLP上进行了预先培训，分别获得了82.1%和80.8%的精确匹配分数。此外，用高兴/愤怒或支持/不支持来替换训练标签的符号来重新表示问题，只会导致性能的轻微下降，因为模型主要依赖于SST的问题指针。这表明，这些多任务模型对于问题和任务中的微小变化更加可靠，并且可以推广到新的和不可见的类。