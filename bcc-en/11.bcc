{"font_size":0.4,"font_color":"#FFFFFF","background_alpha":0.5,"background_color":"#9C27B0","Stroke":"none","body":[{"from":4.28,"to":7.62,"location":2,"content":"The plan for today is what I am gonna talk about"},{"from":7.62,"to":10.71,"location":2,"content":"is the topic of convolutional neural networks."},{"from":10.71,"to":13.92,"location":2,"content":"So essentially, um, there's actually quite a lot of"},{"from":13.92,"to":17.7,"location":2,"content":"content in this lecture of different things that's good to know about,"},{"from":17.7,"to":20.76,"location":2,"content":"since essentially this is going to be learn about"},{"from":20.76,"to":24.84,"location":2,"content":"convolutional neural networks in one large bite for NLP."},{"from":24.84,"to":27.46,"location":2,"content":"So, um, bit on announcements,"},{"from":27.46,"to":30.95,"location":2,"content":"explain the general idea of convolutional neural networks,"},{"from":30.95,"to":33.27,"location":2,"content":"and then for quite a bit of it,"},{"from":33.27,"to":38.49,"location":2,"content":"I want to go through in sort of some detail to particular papers that made"},{"from":38.49,"to":40.95,"location":2,"content":"use of convolutional neural networks for"},{"from":40.95,"to":44.23,"location":2,"content":"text classification, sentence classification tasks."},{"from":44.23,"to":47.04,"location":2,"content":"Um, the first is a sort of a pretty simple,"},{"from":47.04,"to":50.37,"location":2,"content":"um, CNN that was done in 2014,"},{"from":50.37,"to":52.37,"location":2,"content":"and then the second one is a"},{"from":52.37,"to":58.44,"location":2,"content":"way more complex CNN that was done much more recently in 2017."},{"from":58.44,"to":61.27,"location":2,"content":"Okay. But first, a couple of announcements."},{"from":61.27,"to":66.36,"location":2,"content":"Um, firstly, the last reminder on the mid-quarter feedback survey."},{"from":66.36,"to":68.7,"location":2,"content":"So tons of you have done the- this already."},{"from":68.7,"to":70.47,"location":2,"content":"Thank you, thank you very much."},{"from":70.47,"to":74.34,"location":2,"content":"Um, but if you'd still be putting it off till the very last minute, um,"},{"from":74.34,"to":77.33,"location":2,"content":"tonight at midnight is your last chance, um,"},{"from":77.33,"to":80.05,"location":2,"content":"to fill in the mid-quarter survey to get your,"},{"from":80.05,"to":83.28,"location":2,"content":"um, to give us feedback and to get your half-a-point."},{"from":83.28,"to":86.99,"location":2,"content":"Um, okay. And then the other thing that you should be thinking about,"},{"from":86.99,"to":89.51,"location":2,"content":"and I know lots of you are thinking about"},{"from":89.51,"to":92.5,"location":2,"content":"since I spent three hours talking to people yesterday,"},{"from":92.5,"to":95.19,"location":2,"content":"um, is about final projects."},{"from":95.19,"to":99.06,"location":2,"content":"Um, and so make sure you've got some plans from that, um,"},{"from":99.06,"to":100.72,"location":2,"content":"in place for, um,"},{"from":100.72,"to":104.64,"location":2,"content":"04:00 p.m, uh, 04:30 p.m. Thursday."},{"from":104.64,"to":107.53,"location":2,"content":"I mean, in particular as we've discussed, um,"},{"from":107.53,"to":112.75,"location":2,"content":"your- part of what you're meant to do this year is to have found some research paper,"},{"from":112.75,"to":117.73,"location":2,"content":"have read it, and have a summary and thoughts as to how it can inform your work."},{"from":117.73,"to":121.55,"location":2,"content":"Um, and then just make sure you have in your calendars, um,"},{"from":121.55,"to":125.73,"location":2,"content":"the final project poster session for CS224n,"},{"from":125.73,"to":129.32,"location":2,"content":"which is gonna be in the evening of Wednesday March 20th,"},{"from":129.32,"to":132.64,"location":2,"content":"and we're holding it at the Alumni Center."},{"from":132.64,"to":139.94,"location":2,"content":"Okay. Um, one more sort of announcement or just general stuff to cogitate."},{"from":139.94,"to":143.06,"location":2,"content":"Um, so we're now officially in the second half of the class."},{"from":143.06,"to":144.54,"location":2,"content":"Congratulations."},{"from":144.54,"to":146.63,"location":2,"content":"Um, and, you know,"},{"from":146.63,"to":151.88,"location":2,"content":"there's sort of still a few things that we want to teach you that are sort of basic,"},{"from":151.88,"to":154.7,"location":2,"content":"and actually convolutional neural networks is one of them."},{"from":154.7,"to":159.95,"location":2,"content":"But, I mean, nevertheless in the second half of the class, I mean,"},{"from":159.95,"to":164.48,"location":2,"content":"things start to change and we're hoping to much more, um,"},{"from":164.48,"to":169.97,"location":2,"content":"prepare you for being real deep learning NLP researchers or practitioners."},{"from":169.97,"to":172.4,"location":2,"content":"And so what does that mean concretely?"},{"from":172.4,"to":175.75,"location":2,"content":"Well, the lectures start to be less"},{"from":175.75,"to":179.66,"location":2,"content":"giving every detail of how to build a very basic thing,"},{"from":179.66,"to":182.63,"location":2,"content":"and more giving you some ideas"},{"from":182.63,"to":185.88,"location":2,"content":"to sort of some of the work that's been done in different areas."},{"from":185.88,"to":188.51,"location":2,"content":"And so to the extent that there's something of interest or"},{"from":188.51,"to":191.38,"location":2,"content":"rele- relevant to a project or things like that."},{"from":191.38,"to":194.36,"location":2,"content":"Um, the hope is that while you can take some initiative to"},{"from":194.36,"to":197.91,"location":2,"content":"find out more about some of the things that are being talked about."},{"from":197.91,"to":202.1,"location":2,"content":"Um, also would really welcome any questions about things that people,"},{"from":202.1,"to":204.44,"location":2,"content":"um, would want to know more about."},{"from":204.44,"to":206.42,"location":2,"content":"And the other thing that you should know about"},{"from":206.42,"to":210.44,"location":2,"content":"deep learning is that once we get past the fundamentals,"},{"from":210.44,"to":213.35,"location":2,"content":"a lot of the stuff we teach just isn't"},{"from":213.35,"to":218.12,"location":2,"content":"really known science or things that people are sure of that,"},{"from":218.12,"to":221.87,"location":2,"content":"you know, most of what I'm teaching in the second half of the course is pretty"},{"from":221.87,"to":226.18,"location":2,"content":"much what people think is good practice in 2019."},{"from":226.18,"to":229.37,"location":2,"content":"But, you know, the fact of the matter is what people think is"},{"from":229.37,"to":233.39,"location":2,"content":"good practice in deep learning has been changing really rapidly."},{"from":233.39,"to":238.33,"location":2,"content":"So if you go back even two years or definitely if you go back four years, right?"},{"from":238.33,"to":241.64,"location":2,"content":"There's just a lot of different things that people used to believe,"},{"from":241.64,"to":244.85,"location":2,"content":"and now people have some different ideas as to what works best."},{"from":244.85,"to":249.53,"location":2,"content":"And it's perfectly clear that come 2021 or 2023,"},{"from":249.53,"to":252.35,"location":2,"content":"there will be some different ideas again as to what,"},{"from":252.35,"to":254.09,"location":2,"content":"um, people think is best."},{"from":254.09,"to":257.75,"location":2,"content":"So you sort of just have to accept that this is, um,"},{"from":257.75,"to":260.63,"location":2,"content":"a nascent rapidly emerging field"},{"from":260.63,"to":264.13,"location":2,"content":"and it's good to understand the fundamentals and how things fit together."},{"from":264.13,"to":267.74,"location":2,"content":"But after that, quite a bit of the knowledge is this is what people"},{"from":267.74,"to":271.28,"location":2,"content":"think is good at the moment and it keeps evolving over time."},{"from":271.28,"to":274.75,"location":2,"content":"And if you want to stay in the field, or doing things with deep learning,"},{"from":274.75,"to":277.5,"location":2,"content":"you kind of still have to keep up with how it changes."},{"from":277.5,"to":279.71,"location":2,"content":"It's called lifelong learning these days."},{"from":279.71,"to":281.81,"location":2,"content":"It's a very trendy concept."},{"from":281.81,"to":285.2,"location":2,"content":"Um, and so as well as the lectures,"},{"from":285.2,"to":289.74,"location":2,"content":"this is also true for the assignments."},{"from":289.74,"to":291.72,"location":2,"content":"Um, and, you know,"},{"from":291.72,"to":297.05,"location":2,"content":"we've been trying to make the assignments so that they started off very introductory,"},{"from":297.05,"to":301.34,"location":2,"content":"and gradually started to use less scaffolding,"},{"from":301.34,"to":303.39,"location":2,"content":"and we're going to hope to, um,"},{"from":303.39,"to":310.53,"location":2,"content":"continue that, um, with the sort of less hand holding in assignment five."},{"from":310.53,"to":313.91,"location":2,"content":"And, you know, I guess what we're hoping to do is prepare you"},{"from":313.91,"to":317.5,"location":2,"content":"both for the final project and for real life."},{"from":317.5,"to":321,"location":2,"content":"I guess I was making an analogy this morning,"},{"from":321,"to":325.37,"location":2,"content":"um, comparing this to the sort of intro CS sequence,"},{"from":325.37,"to":329.13,"location":2,"content":"so when there's CS106A and B that have tons of scaffolding,"},{"from":329.13,"to":331.02,"location":2,"content":"and then in CS107,"},{"from":331.02,"to":334.85,"location":2,"content":"you're meant to learn how to diagnose and solve problems"},{"from":334.85,"to":338.91,"location":2,"content":"for yourself in a debugger that is kind of the same,"},{"from":338.91,"to":341.01,"location":2,"content":"um, for neural networks that, you know,"},{"from":341.01,"to":343.77,"location":2,"content":"for the early assignments, um, you know,"},{"from":343.77,"to":346.61,"location":2,"content":"we've given you every bit of handholding here, all of"},{"from":346.61,"to":349.49,"location":2,"content":"these tests to make sure every little bit of it is okay,"},{"from":349.49,"to":351.81,"location":2,"content":"and here's exactly how to structure things."},{"from":351.81,"to":354.31,"location":2,"content":"But, you know, in the real world,"},{"from":354.31,"to":357.69,"location":2,"content":"um, you're only going to be able to build and use neural networks."},{"from":357.69,"to":360.26,"location":2,"content":"If you can figure out why they're not working"},{"from":360.26,"to":362.99,"location":2,"content":"and what you have to change to make them work."},{"from":362.99,"to":366.79,"location":2,"content":"And, you know, the truth is as I talked a bit about last week, you know,"},{"from":366.79,"to":371.21,"location":2,"content":"that's often well more than half of the job that it seems easy enough to stick down."},{"from":371.21,"to":374.27,"location":2,"content":"Here's my neural net and the pieces that make sense to me,"},{"from":374.27,"to":377.66,"location":2,"content":"and then you can spend the remaining 80 percent of the time"},{"from":377.66,"to":381.23,"location":2,"content":"scratching your head wondering why it doesn't actually work well,"},{"from":381.23,"to":384.33,"location":2,"content":"and how you could change it to make it to work well."},{"from":384.33,"to":389.81,"location":2,"content":"Um, so, um, I confess that debugging neural nets can often be hard, but, you know,"},{"from":389.81,"to":394.19,"location":2,"content":"the goal is that you should actually learn something about doing it,"},{"from":394.19,"to":398.6,"location":2,"content":"and that's kind of one of the learning goals of the course when it comes down to it."},{"from":398.6,"to":401.05,"location":2,"content":"Um, final little advertisement."},{"from":401.05,"to":403.37,"location":2,"content":"If you feel like you'd like to read a book,"},{"from":403.37,"to":405.15,"location":2,"content":"um, just out this week,"},{"from":405.15,"to":408.31,"location":2,"content":"there's a new book on natural language processing with PyTorch"},{"from":408.31,"to":411.57,"location":2,"content":"by Delip Rao and Brian McMahan."},{"from":411.57,"to":413.99,"location":2,"content":"Delip actually lives in San Francisco."},{"from":413.99,"to":416.66,"location":2,"content":"Um, so, um, if you want to,"},{"from":416.66,"to":418.31,"location":2,"content":"you can buy a copy of this, of course."},{"from":418.31,"to":420.23,"location":2,"content":"But if you don't want to, um,"},{"from":420.23,"to":423.23,"location":2,"content":"buy it and you feel like having a bit of a look through it, um,"},{"from":423.23,"to":429.11,"location":2,"content":"the Stanford library is actually has a license to the O'Reilly's Safari Books collection."},{"from":429.11,"to":434.94,"location":2,"content":"So you can start off at library.stanford.edu and read it for free."},{"from":434.94,"to":438.23,"location":2,"content":"There's one catch to this which is the library only has"},{"from":438.23,"to":441.71,"location":2,"content":"16 simultaneous licenses to Safari Books."},{"from":441.71,"to":445.45,"location":2,"content":"So if you'd also like your classmates to be able to read it for free,"},{"from":445.45,"to":449.94,"location":2,"content":"it really helps if you remember to log out of Safari Books Online,"},{"from":449.94,"to":452.27,"location":2,"content":"um, when you're done looking at it."},{"from":452.27,"to":454.79,"location":2,"content":"Um, yes, so this is sort of a,"},{"from":454.79,"to":456.42,"location":2,"content":"I mean, in some sense,"},{"from":456.42,"to":459.02,"location":2,"content":"I hope you will feel if you look at this book,"},{"from":459.02,"to":461.61,"location":2,"content":"\"Boy, I already know most of that stuff already."},{"from":461.61,"to":463.74,"location":2,"content":"It's not a super advanced book."},{"from":463.74,"to":469.78,"location":2,"content":"But it's a good well-written tutorial of how to do things with PyTorch and NLP.\""},{"from":469.78,"to":472.62,"location":2,"content":"If you don't feel like you know most of the stuff in this book,"},{"from":472.62,"to":476.25,"location":2,"content":"you can let me know but I will be a little sad."},{"from":476.25,"to":481.03,"location":2,"content":"Um, okay, um, yeah."},{"from":481.03,"to":483.76,"location":2,"content":"So, let, so starting into today."},{"from":483.76,"to":486.43,"location":2,"content":"Um, so, we spent a lot of time on"},{"from":486.43,"to":490.63,"location":2,"content":"recurrent neural networks and they are great for many things."},{"from":490.63,"to":495.67,"location":2,"content":"Um, but there's sort of some things that they're not so good at."},{"from":495.67,"to":501.28,"location":2,"content":"So, you know, we kind of might like to know about a phrase like my birth,"},{"from":501.28,"to":503.8,"location":2,"content":"or a bigger phrase like of my birth,"},{"from":503.8,"to":507.55,"location":2,"content":"and there's sort of no independent, um,"},{"from":507.55,"to":511.48,"location":2,"content":"representation of those spans in a recurrent neural network."},{"from":511.48,"to":515.37,"location":2,"content":"We kind of get sort of prefixes of a whole sentence."},{"from":515.37,"to":518.82,"location":2,"content":"And while we did, um, bidirectional, um,"},{"from":518.82,"to":522.1,"location":2,"content":"recurrent neural networks, and you could say, 'Well,"},{"from":522.1,"to":525.67,"location":2,"content":"wait a minute you could use it in both directions' and to some extent that's true."},{"from":525.67,"to":529.12,"location":2,"content":"We can get stuff from this direction and stuff from this direction,"},{"from":529.12,"to":531.26,"location":2,"content":"but we still kind of have sort of"},{"from":531.26,"to":534.73,"location":2,"content":"whole sequences that go to one end of the sentence or another."},{"from":534.73,"to":537.79,"location":2,"content":"We don't just have pieces of sentences."},{"from":537.79,"to":543.6,"location":2,"content":"And often, we'd like to sort of work out meanings of pieces of sentences,"},{"from":543.6,"to":546.28,"location":2,"content":"and so, we sort of have two problems here."},{"from":546.28,"to":549.84,"location":2,"content":"We only have sort of initial and final sub-sequences."},{"from":549.84,"to":554.23,"location":2,"content":"And also, if you look at these representations, like if you say,"},{"from":554.23,"to":558.82,"location":2,"content":"take this last state as the representation of the meaning of this text."},{"from":558.82,"to":560.08,"location":2,"content":"What you find out,"},{"from":560.08,"to":562.36,"location":2,"content":"is it's very dominated by the meaning of"},{"from":562.36,"to":567.64,"location":2,"content":"the most recent words and what they are trying to predict as to what comes after them,"},{"from":567.64,"to":570.09,"location":2,"content":"and that's part of the reason why I mentioned"},{"from":570.09,"to":573.28,"location":2,"content":"last time in the question answering, um, lecture,"},{"from":573.28,"to":577.06,"location":2,"content":"the idea that well you can do better by having a sentinel and training"},{"from":577.06,"to":581.75,"location":2,"content":"something that has attention over the whole, um, LSTM structure."},{"from":581.75,"to":584.56,"location":2,"content":"Okay. But today we're going to look at"},{"from":584.56,"to":588.57,"location":2,"content":"a different alternative which is convolutional neural nets,"},{"from":588.57,"to":593.49,"location":2,"content":"which are often abbreviated as either CNN's or ConvNets."},{"from":593.49,"to":597.38,"location":2,"content":"Um, and the idea of these is, well,"},{"from":597.38,"to":599.92,"location":2,"content":"look maybe we could just take"},{"from":599.92,"to":606.91,"location":2,"content":"every sub-sequence of a certain length and calculate a representation for it, um,"},{"from":606.91,"to":610.09,"location":2,"content":"so that, you know, if we have some piece of text like,"},{"from":610.09,"to":612.68,"location":2,"content":"tentative deal reached to keep government open,"},{"from":612.68,"to":614.32,"location":2,"content":"and we could sort of just say, well,"},{"from":614.32,"to":617.11,"location":2,"content":"let's just take all three words sequences,"},{"from":617.11,"to":619.76,"location":2,"content":"tentative deal reached, deal reached to,"},{"from":619.76,"to":621.38,"location":2,"content":"reached to keep et cetera,"},{"from":621.38,"to":626.47,"location":2,"content":"and we're going to calculate some kind of representation for each of those sequences."},{"from":626.47,"to":630.25,"location":2,"content":"So, this is an- isn't a strongly linguistic idea."},{"from":630.25,"to":633.43,"location":2,"content":"Right? We're not worrying about whether it's a coherent phrase,"},{"from":633.43,"to":636.31,"location":2,"content":"that's grammatical linguistically valid,"},{"from":636.31,"to":641.13,"location":2,"content":"cognitively plausible, we're just taking every sub-sequence of a certain length."},{"from":641.13,"to":645.37,"location":2,"content":"And then, once we've calculated representations of those,"},{"from":645.37,"to":648.02,"location":2,"content":"we're going to look at how to group them."},{"from":648.02,"to":655.9,"location":2,"content":"Okay. So, let's get into more detail as to what CNN's are and how they work."},{"from":655.9,"to":661.9,"location":2,"content":"Um, yeah, so, there's this general idea of a convolution which you may or may"},{"from":661.9,"to":667.86,"location":2,"content":"not have seen in some math or electrical engineering class."},{"from":667.86,"to":672.01,"location":2,"content":"And then, there's the particular version of convolutions,"},{"from":672.01,"to":675.31,"location":2,"content":"the discrete convolutions, which you can means that"},{"from":675.31,"to":678.91,"location":2,"content":"you can use the friendly summation symbol rather than an integral."},{"from":678.91,"to":680.9,"location":2,"content":"Um, and that's a,"},{"from":680.9,"to":682.48,"location":2,"content":"that's a discrete convolution."},{"from":682.48,"to":685.5,"location":2,"content":"I find that that notation as completely unhelpful."},{"from":685.5,"to":687.04,"location":2,"content":"So, I won't even try and explain it."},{"from":687.04,"to":688.69,"location":2,"content":"But I've got lots of examples,"},{"from":688.69,"to":694.08,"location":2,"content":"and convolutions are really easy for neural nets in terms of what they do for examples."},{"from":694.08,"to":698.59,"location":2,"content":"All right, so the classic case of where convolutional neural networks are used,"},{"from":698.59,"to":700.27,"location":2,"content":"is in vision applications."},{"from":700.27,"to":704.61,"location":2,"content":"So, if you do CS231N next quarter,"},{"from":704.61,"to":707.77,"location":2,"content":"essentially you know,  the first four weeks is just all doing"},{"from":707.77,"to":711.72,"location":2,"content":"convolutional neural networks in all their variants and glory."},{"from":711.72,"to":715.54,"location":2,"content":"Um, and the sort of essential idea of, um,"},{"from":715.54,"to":717.89,"location":2,"content":"convolutions for a vision,"},{"from":717.89,"to":722.41,"location":2,"content":"is that you want to recognize things no matter where they appear in an image."},{"from":722.41,"to":725.62,"location":2,"content":"So, you have a sort of property of translation and variance,"},{"from":725.62,"to":728.23,"location":2,"content":"and the idea of a convolution as a way"},{"from":728.23,"to":730.81,"location":2,"content":"of finding something in different places in the image,"},{"from":730.81,"to":732.67,"location":2,"content":"regardless of where it appears."},{"from":732.67,"to":739.36,"location":2,"content":"Um, so this is the vision example which I stole from Andrew Ng's UFLDL website."},{"from":739.36,"to":741.92,"location":2,"content":"And so, what a convolution is,"},{"from":741.92,"to":744.13,"location":2,"content":"is it's here a patch,"},{"from":744.13,"to":746.82,"location":2,"content":"but you can think of it as just as a vector,"},{"from":746.82,"to":751.45,"location":2,"content":"and the patch has weights which are these little numbers in red,"},{"from":751.45,"to":753,"location":2,"content":"and what you're gonna do,"},{"from":753,"to":760.35,"location":2,"content":"is slide that patch over the image as this as this animation does."},{"from":760.35,"to":763.08,"location":2,"content":"Um, and so at each position,"},{"from":763.08,"to":767.9,"location":2,"content":"you're going to multiply each of the red numbers by the black number in that position,"},{"from":767.9,"to":770.08,"location":2,"content":"and then you're just going to sum them up."},{"from":770.08,"to":773.25,"location":2,"content":"So, that's what a discrete convolution does,"},{"from":773.25,"to":775.18,"location":2,"content":"which is what that notation at the top is saying,"},{"from":775.18,"to":778.5,"location":2,"content":"right? You're multiplying things together and then you're summing them up,"},{"from":778.5,"to":780.24,"location":2,"content":"and so you're doing this,"},{"from":780.24,"to":784.24,"location":2,"content":"and then you're filling in the pink with the products,"},{"from":784.24,"to":785.71,"location":2,"content":"um, the sum products."},{"from":785.71,"to":787.86,"location":2,"content":"So, it's sort of like, you're taking these sort of"},{"from":787.86,"to":792.4,"location":2,"content":"patch dot products and putting them into the pink matrix,"},{"from":792.4,"to":794.82,"location":2,"content":"and that's then your convolved feature."},{"from":794.82,"to":797.35,"location":2,"content":"So, that's a 2D convolution,"},{"from":797.35,"to":798.76,"location":2,"content":"which for the rest of today,"},{"from":798.76,"to":800.47,"location":2,"content":"we're not going to look at anymore."},{"from":800.47,"to":803.22,"location":2,"content":"So, this is all you're learning about vision."},{"from":803.22,"to":808.39,"location":2,"content":"Um, and so we're now going to go back and look at 1D convolutions,"},{"from":808.39,"to":813,"location":2,"content":"which is what people use when they're using convolutional neural networks for text."},{"from":813,"to":816.61,"location":2,"content":"So, the starting point of a convolutional neural network for text,"},{"from":816.61,"to":818.41,"location":2,"content":"is we have an input."},{"from":818.41,"to":822.19,"location":2,"content":"So, here's my sentence and for each word"},{"from":822.19,"to":825.97,"location":2,"content":"in the sentence I have here got a dense word vector,"},{"from":825.97,"to":831.33,"location":2,"content":"I made it a 4D, want to keep it small in my example but usually as you know, it's more."},{"from":831.33,"to":834.58,"location":2,"content":"So, our starting point is we have some input, you know,"},{"from":834.58,"to":838.06,"location":2,"content":"input could just be a one-hot encoding that's not forbidden here,"},{"from":838.06,"to":841.79,"location":2,"content":"but normally we'll have these kind of dense word vectors."},{"from":841.79,"to":846.31,"location":2,"content":"And so, then it's sort of the same as the 3D as the 2D one,"},{"from":846.31,"to":848.18,"location":2,"content":"apart from we've only got one dimension."},{"from":848.18,"to":850.51,"location":2,"content":"So, we have a filter."},{"from":850.51,"to":854.41,"location":2,"content":"Um, so here is our filter,"},{"from":854.41,"to":861.75,"location":2,"content":"and so our filter is gonna do three steps and time, three words."},{"from":861.75,"to":865.93,"location":2,"content":"And that's going to work across the dimensions."},{"from":865.93,"to":868.24,"location":2,"content":"So, these different dimensions in"},{"from":868.24,"to":872.5,"location":2,"content":"the convolutional neural network often get referred to as channels."},{"from":872.5,"to":875.66,"location":2,"content":"So, we're kind of working across the input channels,"},{"from":875.66,"to":877.99,"location":2,"content":"and so we have a patch like this."},{"from":877.99,"to":885.43,"location":2,"content":"And we're going to take this patch and put it on top of the first three words."},{"from":885.43,"to":887.98,"location":2,"content":"I don't have as good an animation as the previous slide."},{"from":887.98,"to":891.61,"location":2,"content":"Sorry. And we're going to work out the dot product,"},{"from":891.61,"to":896.41,"location":2,"content":"um, between those, and I did that at home by putting this into Excel."},{"from":896.41,"to":898.01,"location":2,"content":"And the answer [LAUGHTER] to that,"},{"from":898.01,"to":901.25,"location":2,"content":"is that the product is minus 1.0."},{"from":901.25,"to":905.5,"location":2,"content":"And then at that point, we slide our,"},{"from":905.5,"to":908.35,"location":2,"content":"We slide this, um,"},{"from":908.35,"to":911.41,"location":2,"content":"matrix which gets referred to as a kernel or"},{"from":911.41,"to":916.3,"location":2,"content":"a filter which is the patch that we're using for our convolutional neural network."},{"from":916.3,"to":921.52,"location":2,"content":"We slide it down one and do the dot product of those terms again."},{"from":921.52,"to":928.96,"location":2,"content":"And that comes out as minus a half and we keep on sliding that down and we get what,"},{"from":928.96,"to":933.1,"location":2,"content":"um, gets what's shown on the right as our output."},{"from":933.1,"to":934.26,"location":2,"content":"So at this point,"},{"from":934.26,"to":936.69,"location":2,"content":"we've just reduced the sentence,"},{"from":936.69,"to":939.11,"location":2,"content":"um, to a single vector."},{"from":939.11,"to":944.74,"location":2,"content":"Um, and that seems like we might want to do more than that."},{"from":944.74,"to":948.46,"location":2,"content":"Um, but the other thing that you will have noticed is that"},{"from":948.46,"to":952.5,"location":2,"content":"our sentence is sort of shrunk because before, you know,"},{"from":952.5,"to":957.71,"location":2,"content":"we had a seven word sentence but because I've just sort of slid this three word,"},{"from":957.71,"to":959.62,"location":2,"content":"um, kernel down here,"},{"from":959.62,"to":963.01,"location":2,"content":"I ended up with only five positions to put it in."},{"from":963.01,"to":965.83,"location":2,"content":"So it's become a five word thing."},{"from":965.83,"to":968.96,"location":2,"content":"Um, so to first of all address that problem,"},{"from":968.96,"to":974.03,"location":2,"content":"commonly when people do convolutional neural networks, they add padding."},{"from":974.03,"to":978.79,"location":2,"content":"Um, so what I can do is I can add zero padding at"},{"from":978.79,"to":985.8,"location":2,"content":"both ends and then sort of do the same trick and say run a convolution on that."},{"from":985.8,"to":991.36,"location":2,"content":"And now, I'll be able to put my size three filter in seven different places as I"},{"from":991.36,"to":997.84,"location":2,"content":"slide it down and so I'm getting out a vector that's the same length of my input."},{"from":997.84,"to":1000.65,"location":2,"content":"Um, that, you know, there are different way,"},{"from":1000.65,"to":1003.2,"location":2,"content":"so this is the most common way of doing things."},{"from":1003.2,"to":1006.76,"location":2,"content":"And it's kind of seems logical because it maintains size."},{"from":1006.76,"to":1010.46,"location":2,"content":"I mean, you know, there's always more than one way to do it."},{"from":1010.46,"to":1012.31,"location":2,"content":"Um, if you really wanted to,"},{"from":1012.31,"to":1014.39,"location":2,"content":"you, oops, I don't want you, yeah,"},{"from":1014.39,"to":1019.56,"location":2,"content":"there, oops, I made, uh,"},{"from":1019.56,"to":1025.86,"location":2,"content":"I made a slight mistake on my slide because this"},{"from":1025.86,"to":1028.4,"location":2,"content":"turns out which I was about to get to in a minute"},{"from":1028.4,"to":1032.79,"location":2,"content":"but I'll just explain this bit here anyway [LAUGHTER]."},{"from":1032.79,"to":1035.45,"location":2,"content":"Um, you know, if you wanted to,"},{"from":1035.45,"to":1039.74,"location":2,"content":"you could have two steps of padding on both ends here."},{"from":1039.74,"to":1044.29,"location":2,"content":"So that your first convolution we'll be looking at zero, zero,"},{"from":1044.29,"to":1050.59,"location":2,"content":"10 to the of and then the convolution would actually grow the size of your input."},{"from":1050.59,"to":1055.91,"location":2,"content":"Yeah. But, yes. So I mean,"},{"from":1055.91,"to":1058.57,"location":2,"content":"so what we've done so far,"},{"from":1058.57,"to":1061.38,"location":2,"content":"we've started with these word vectors which in"},{"from":1061.38,"to":1066.34,"location":2,"content":"convolutional neural networks terms were of length four."},{"from":1066.34,"to":1069.47,"location":2,"content":"So our kind of input had four channels."},{"from":1069.47,"to":1073.03,"location":2,"content":"But when we were back here, um,"},{"from":1073.03,"to":1076.52,"location":2,"content":"we were just producing from this, um,"},{"from":1076.52,"to":1079.69,"location":2,"content":"kernel, one column of output."},{"from":1079.69,"to":1082.56,"location":2,"content":"So our output has only a single channel."},{"from":1082.56,"to":1088.69,"location":2,"content":"So we've sort of shrunk things in the columns direction from four to one."},{"from":1088.69,"to":1091.49,"location":2,"content":"And that might seem bad."},{"from":1091.49,"to":1094.11,"location":2,"content":"And for many purposes, it is bad."},{"from":1094.11,"to":1096.71,"location":2,"content":"Um, and so, a lot of the time,"},{"from":1096.71,"to":1101.16,"location":2,"content":"what you want to do is to say,"},{"from":1101.16,"to":1105.33,"location":2,"content":"well, rather than have only one filter,"},{"from":1105.33,"to":1109.26,"location":2,"content":"instead of that, why don't I have several filters?"},{"from":1109.26,"to":1112.68,"location":2,"content":"So here I've got three different filters and each of"},{"from":1112.68,"to":1116.62,"location":2,"content":"these filters is just sort of the same size three,"},{"from":1116.62,"to":1121.83,"location":2,"content":"three the size, the kernel size times the input,"},{"from":1121.83,"to":1126.14,"location":2,"content":"number of channels for the matrix."},{"from":1126.14,"to":1129.55,"location":2,"content":"So I have three different filters and I'm going to run"},{"from":1129.55,"to":1133.38,"location":2,"content":"each one down the text and get a column here."},{"from":1133.38,"to":1136.51,"location":2,"content":"So now, I'm ending up with three columns of output."},{"from":1136.51,"to":1139.67,"location":2,"content":"And so I have this sort of a three channel output."},{"from":1139.67,"to":1144.94,"location":2,"content":"And the way to intuitively think of this is for these filters,"},{"from":1144.94,"to":1147.51,"location":2,"content":"well, you know, for what we do in neural networks,"},{"from":1147.51,"to":1151.04,"location":2,"content":"we're going to learn them by backpropagation like everything else."},{"from":1151.04,"to":1156.76,"location":2,"content":"But our hope is that these filters could somehow specialize in different things."},{"from":1156.76,"to":1160.48,"location":2,"content":"So maybe this filter could specialize on,"},{"from":1160.48,"to":1162.36,"location":2,"content":"is this language polite?"},{"from":1162.36,"to":1166.72,"location":2,"content":"And it will produce a high value whenever it sees polite words."},{"from":1166.72,"to":1169.85,"location":2,"content":"And maybe, um, this, um,"},{"from":1169.85,"to":1175.61,"location":2,"content":"filter could specialize on, I don't know,"},{"from":1175.61,"to":1178.8,"location":2,"content":"eating and it will have a high value whenever it sees words"},{"from":1178.8,"to":1182.43,"location":2,"content":"about food and you know this filter will do a third thing."},{"from":1182.43,"to":1189.23,"location":2,"content":"And so that's the sense in which people sometimes talk about, um, the, um,"},{"from":1189.23,"to":1193.08,"location":2,"content":"what you're getting is output of different features because your hope is that"},{"from":1193.08,"to":1197.52,"location":2,"content":"you'll kind of gain different latent features coming out of the text."},{"from":1197.52,"to":1202.56,"location":2,"content":"Okay. So that gives us a representation and that's sort of"},{"from":1202.56,"to":1207.54,"location":2,"content":"a useful sort of having found learn features in our text."},{"from":1207.54,"to":1211.29,"location":2,"content":"That quite often though, what we'll want to do is just"},{"from":1211.29,"to":1215.61,"location":2,"content":"summarize the text with re- with respect to those features."},{"from":1215.61,"to":1218.03,"location":2,"content":"So you might just have the question of, well,"},{"from":1218.03,"to":1220.05,"location":2,"content":"in this piece of text, um,"},{"from":1220.05,"to":1223.43,"location":2,"content":"is it polite and does it talk about food?"},{"from":1223.43,"to":1226.56,"location":2,"content":"So another operation that we'll quite often"},{"from":1226.56,"to":1230.41,"location":2,"content":"do is wanna summarize the output of a convolutional network."},{"from":1230.41,"to":1232.75,"location":2,"content":"And the simplest way to do that,"},{"from":1232.75,"to":1235.11,"location":2,"content":"is for 1D convolutions,"},{"from":1235.11,"to":1237.63,"location":2,"content":"is called max pooling over time."},{"from":1237.63,"to":1240.08,"location":2,"content":"So if we max pool over time,"},{"from":1240.08,"to":1243.93,"location":2,"content":"that each of the channels or otherwise known as features,"},{"from":1243.93,"to":1253.87,"location":2,"content":"we're just simply going to look down and see what is its maximum value, 0.3, 1.6, 1.4."},{"from":1253.87,"to":1255.78,"location":2,"content":"Um, and so, you know,"},{"from":1255.78,"to":1258.73,"location":2,"content":"if I use my story about the first two, um,"},{"from":1258.73,"to":1260.7,"location":2,"content":"filters, it's sort of saying, well,"},{"from":1260.7,"to":1264.6,"location":2,"content":"it's not very polite text but it's really about food, right?"},{"from":1264.6,"to":1266.3,"location":2,"content":"That we're sort of summarizing,"},{"from":1266.3,"to":1268.46,"location":2,"content":"um, what we've detected there."},{"from":1268.46,"to":1274.4,"location":2,"content":"Um, so the concept of max pooling in some sense captures,"},{"from":1274.4,"to":1278.64,"location":2,"content":"does, is this thing being activated anywhere, right?"},{"from":1278.64,"to":1282.18,"location":2,"content":"So if we have things like politeness and about food,"},{"from":1282.18,"to":1285.51,"location":2,"content":"that the output of max pooling will have a high value."},{"from":1285.51,"to":1288.6,"location":2,"content":"If somewhere in the sentence there was a clear marker of"},{"from":1288.6,"to":1292.04,"location":2,"content":"politeness or something clearly about food."},{"from":1292.04,"to":1297.21,"location":2,"content":"And that's often a useful notion because often what you want to know is,"},{"from":1297.21,"to":1302.26,"location":2,"content":"you know, is there some discussion of food in this sentence or is there not?"},{"from":1302.26,"to":1306.15,"location":2,"content":"There's another thing, there are other things that you could do."},{"from":1306.15,"to":1308.63,"location":2,"content":"Instead of, ah, max pooling,"},{"from":1308.63,"to":1311.21,"location":2,"content":"you can instead do average pooling."},{"from":1311.21,"to":1315.4,"location":2,"content":"So here you just take these numbers and find the average of them."},{"from":1315.4,"to":1318.91,"location":2,"content":"That then has the different semantics which is sort of"},{"from":1318.91,"to":1322.6,"location":2,"content":"what's the average amount of politeness of this, um,"},{"from":1322.6,"to":1325.86,"location":2,"content":"text or on average how much, you know, how,"},{"from":1325.86,"to":1330.27,"location":2,"content":"what percent of the sentence is about food or something like that."},{"from":1330.27,"to":1332.19,"location":2,"content":"Um, for some purposes,"},{"from":1332.19,"to":1333.68,"location":2,"content":"this is better because, you know,"},{"from":1333.68,"to":1336.96,"location":2,"content":"it takes in all of the important builds to an average."},{"from":1336.96,"to":1338.9,"location":2,"content":"I mean, a lot of the time,"},{"from":1338.9,"to":1342.89,"location":2,"content":"people have found that actually max pooling is better because,"},{"from":1342.89,"to":1347.49,"location":2,"content":"you know, a lot of signals in natural language are sparse."},{"from":1347.49,"to":1350.63,"location":2,"content":"You know, no matter how polite you are trying to be,"},{"from":1350.63,"to":1352.94,"location":2,"content":"you're not going to be being polite in every word."},{"from":1352.94,"to":1357.43,"location":2,"content":"You're going to say nouns and articles like that and a,"},{"from":1357.43,"to":1360.39,"location":2,"content":"and prepositions and conjunctions,"},{"from":1360.39,"to":1362.63,"location":2,"content":"none of which are inherently polite, right?"},{"from":1362.63,"to":1366.33,"location":2,"content":"Um, so that if there's some politeness showing up prominently,"},{"from":1366.33,"to":1371.47,"location":2,"content":"then the sentence becomes polite and max pooling is actually better for capturing that."},{"from":1371.47,"to":1374.43,"location":2,"content":"Um, of course the one other kind of thing that you can do as"},{"from":1374.43,"to":1378.12,"location":2,"content":"min pooling and find the least [LAUGHTER] active thing."},{"from":1378.12,"to":1381.13,"location":2,"content":"Um, it doesn't get used much but you could do that as well."},{"from":1381.13,"to":1384.38,"location":2,"content":"Okay. So, um, so if you're in PyTorch,"},{"from":1384.38,"to":1387.37,"location":2,"content":"this is all pretty easy stuff to do."},{"from":1387.37,"to":1390.01,"location":2,"content":"So there's a handy dandy Conv1d."},{"from":1390.01,"to":1393.03,"location":2,"content":"There's also a Conv2d as you might guess for vision."},{"from":1393.03,"to":1395.01,"location":2,"content":"But there's a Conv1d, um,"},{"from":1395.01,"to":1398.79,"location":2,"content":"where you're specifying how many input channels there are."},{"from":1398.79,"to":1400.72,"location":2,"content":"That was our word embedding size."},{"from":1400.72,"to":1402.73,"location":2,"content":"How many output channels there are?"},{"from":1402.73,"to":1404.37,"location":2,"content":"We have three."},{"from":1404.37,"to":1407.82,"location":2,"content":"What the size of the convolutional kernel is?"},{"from":1407.82,"to":1409.53,"location":2,"content":"So the ones that we were showing were also"},{"from":1409.53,"to":1412.38,"location":2,"content":"three and then there are various other parameters you can have."},{"from":1412.38,"to":1415.99,"location":2,"content":"Like you can say that you want a padding of one and things like that."},{"from":1415.99,"to":1418.08,"location":2,"content":"And then once you've got one of those,"},{"from":1418.08,"to":1419.69,"location":2,"content":"you can just sort of run"},{"from":1419.69,"to":1424.36,"location":2,"content":"your convolutional filter on the input to get a new hidden state."},{"from":1424.36,"to":1426.22,"location":2,"content":"And then if you wanna max pool,"},{"from":1426.22,"to":1427.57,"location":2,"content":"you can just max,"},{"from":1427.57,"to":1431.75,"location":2,"content":"um, through the output of that and then you've got a max pooled output."},{"from":1431.75,"to":1438.87,"location":2,"content":"Okay. So that gives us the basics of building a kind of a convolutional neural network,"},{"from":1438.87,"to":1441.15,"location":2,"content":"um, for, um, NLP."},{"from":1441.15,"to":1446,"location":2,"content":"Does that sort of makes sense up until there?"},{"from":1446,"to":1450.57,"location":2,"content":"Yeah. Okay. So next bit is to sort of show"},{"from":1450.57,"to":1455.27,"location":2,"content":"you three or four other things that you can do."},{"from":1455.27,"to":1458.33,"location":2,"content":"Um, I started off typing these slides"},{"from":1458.33,"to":1460.92,"location":2,"content":"other less useful notions because I"},{"from":1460.92,"to":1463.59,"location":2,"content":"kinda thought, oh, at least they don't really come up much in NLP."},{"from":1463.59,"to":1468.09,"location":2,"content":"But, you know, actually it turned out when I got on to that second paper,"},{"from":1468.09,"to":1472.74,"location":2,"content":"when I say the complex convolutional neural network, actually,"},{"from":1472.74,"to":1477.75,"location":2,"content":"in that paper they try out just about all of these things that I say no one uses."},{"from":1477.75,"to":1482.14,"location":2,"content":"So it's sort of good to know what they are for looking at various papers."},{"from":1482.14,"to":1489.8,"location":2,"content":"So here, when we did things so far then we were calculating these convolutions,"},{"from":1489.8,"to":1492.66,"location":2,"content":"that we're sort of trying them out at every position."},{"from":1492.66,"to":1495.29,"location":2,"content":"So we had one for zero, tentative deal."},{"from":1495.29,"to":1498.42,"location":2,"content":"Then for tentative deal reached then deal reached to."},{"from":1498.42,"to":1500.97,"location":2,"content":"And so we were just walking down one step at"},{"from":1500.97,"to":1504.77,"location":2,"content":"a time which is referred to as a stride as, of one."},{"from":1504.77,"to":1508.1,"location":2,"content":"And that's by far the most common thing to do."},{"from":1508.1,"to":1509.6,"location":2,"content":"But you could observe,"},{"from":1509.6,"to":1510.83,"location":2,"content":"look wait a minute,"},{"from":1510.83,"to":1515.65,"location":2,"content":"since the first convolution concerns zero tentative deal."},{"from":1515.65,"to":1518.09,"location":2,"content":"I've got all those three words in there."},{"from":1518.09,"to":1525.22,"location":2,"content":"Even if I skip down to a next did, deal reach to and then I did to keep government,"},{"from":1525.22,"to":1530.46,"location":2,"content":"I'd still have in one or other of the convolutions every word of the sentence"},{"from":1530.46,"to":1532.95,"location":2,"content":"so I can do half as much computation and I've"},{"from":1532.95,"to":1535.63,"location":2,"content":"still got everything in there in some sense."},{"from":1535.63,"to":1538.42,"location":2,"content":"And so that's referred to as using a stride of two."},{"from":1538.42,"to":1542.13,"location":2,"content":"And so then I get something with half as many rows out."},{"from":1542.13,"to":1546.84,"location":2,"content":"So it's one way to sort of compactify your representation and produce"},{"from":1546.84,"to":1552.86,"location":2,"content":"something shorter from a longer sentence and we'll see that use of it coming up later."},{"from":1552.86,"to":1559.89,"location":2,"content":"There's other ways to compactify what cut representation that comes out of your sentence."},{"from":1559.89,"to":1565.71,"location":2,"content":"And so there's a different notion of pooling which is local pooling."},{"from":1565.71,"to":1569.64,"location":2,"content":"Now, if if you've seen any of"},{"from":1569.64,"to":1573.51,"location":2,"content":"the vision world when people talk about max pooling and vision,"},{"from":1573.51,"to":1576.96,"location":2,"content":"they normally mean local pooling as opposed to"},{"from":1576.96,"to":1581.4,"location":2,"content":"the max pooling through time that I showed you first."},{"from":1581.4,"to":1587.07,"location":2,"content":"So here we're sort of back to where we started and we've done"},{"from":1587.07,"to":1593.54,"location":2,"content":"our size three stride one convolution which is producing output as before."},{"from":1593.54,"to":1599.31,"location":2,"content":"But now, what I'm gonna do is local pool with a stride of two."},{"from":1599.31,"to":1604.65,"location":2,"content":"Which means I'm gonna take each two rows and I'm gonna pool them together into"},{"from":1604.65,"to":1607.11,"location":2,"content":"one row and I could do that again by"},{"from":1607.11,"to":1610.68,"location":2,"content":"either maxing or averaging or whatever appeals to me."},{"from":1610.68,"to":1613.2,"location":2,"content":"So I take the first two rows,"},{"from":1613.2,"to":1614.97,"location":2,"content":"I max pool them I get this."},{"from":1614.97,"to":1616.8,"location":2,"content":"I take the next two rows,"},{"from":1616.8,"to":1618.56,"location":2,"content":"I max pool them I get this."},{"from":1618.56,"to":1621.42,"location":2,"content":"Next two, next two and I sort of pad it"},{"from":1621.42,"to":1624.29,"location":2,"content":"on the bottom so I have two rows at the bottom."},{"from":1624.29,"to":1629.41,"location":2,"content":"And so that's then give me a local max pooling of a stride of two."},{"from":1629.41,"to":1633.3,"location":2,"content":"And that sort of had exactly the same effect in the sense but"},{"from":1633.3,"to":1636.99,"location":2,"content":"with a different result as using a stride of two in"},{"from":1636.99,"to":1640.53,"location":2,"content":"my convolution because I have again reduced it to"},{"from":1640.53,"to":1646.97,"location":2,"content":"something of four rows that used to be eight rows."},{"from":1646.97,"to":1649.93,"location":2,"content":"Yeah, picture that."},{"from":1649.93,"to":1653.64,"location":2,"content":"Okay so that's that one."},{"from":1653.64,"to":1655.41,"location":2,"content":"What else can you do."},{"from":1655.41,"to":1658.08,"location":2,"content":"There are more things you can do to make it complex."},{"from":1658.08,"to":1663.77,"location":2,"content":"Another thing that people have sometimes done is k-max pooling."},{"from":1663.77,"to":1669.51,"location":2,"content":"And so this is a more complex thing and it's sort of saying well,"},{"from":1669.51,"to":1673.53,"location":2,"content":"rather than just keeping the max over time,"},{"from":1673.53,"to":1680.33,"location":2,"content":"if a feature is being kind of activated two or three times in the sentence,"},{"from":1680.33,"to":1683.64,"location":2,"content":"maybe it'd be good to record all the times that it's"},{"from":1683.64,"to":1687.38,"location":2,"content":"activated in the sentence while throwing away the rest."},{"from":1687.38,"to":1689.07,"location":2,"content":"So in k-max pooling,"},{"from":1689.07,"to":1690.87,"location":2,"content":"and I'm doing two max here,"},{"from":1690.87,"to":1697.34,"location":2,"content":"you look down this column and you find the two highest values for that column."},{"from":1697.34,"to":1703.66,"location":2,"content":"But then you put the two highest values not in the order of highest to lowest,"},{"from":1703.66,"to":1706.62,"location":2,"content":"but in the order in which they are in these columns."},{"from":1706.62,"to":1708.84,"location":2,"content":"So it's minus 0.2,"},{"from":1708.84,"to":1712.23,"location":2,"content":"0.3 for this one and it's 1.6,"},{"from":1712.23,"to":1718.07,"location":2,"content":"0.6 for this one because it reflects the orders of the columns up above."},{"from":1718.07,"to":1723.21,"location":2,"content":"Okay. Almost done, one more concept."},{"from":1723.21,"to":1732.29,"location":2,"content":"This is another way of compressing data which is a dilated convolution."},{"from":1732.29,"to":1735.32,"location":2,"content":"So if you have a dilated convolution,"},{"from":1735.32,"to":1741.87,"location":2,"content":"so dilated convolution doing it over here doesn't really make sense but where you can use"},{"from":1741.87,"to":1748.44,"location":2,"content":"a dilated convolution is if I take this and put it through another convolutional layer,"},{"from":1748.44,"to":1753.54,"location":2,"content":"we can kind of have deep convolutional networks that have multiple convolutional layers."},{"from":1753.54,"to":1760.56,"location":2,"content":"So the idea of a dilated convolution issue is you're gonna skip some of the rows."},{"from":1760.56,"to":1764.3,"location":2,"content":"So if you use a dilation of two starting at the top,"},{"from":1764.3,"to":1767.46,"location":2,"content":"you're going to take the first, third,"},{"from":1767.46,"to":1771.87,"location":2,"content":"and the fifth row and multiply them by my fil- sorry,"},{"from":1771.87,"to":1772.98,"location":2,"content":"I have different filters."},{"from":1772.98,"to":1778.31,"location":2,"content":"Multiply them by my filters and then get the values that appear here."},{"from":1778.31,"to":1780.48,"location":2,"content":"And then if stride as one,"},{"from":1780.48,"to":1786.9,"location":2,"content":"you'd then use, you would go on and sort of do the next spread out rows."},{"from":1786.9,"to":1791.03,"location":2,"content":"And so this allows you to have convolutions that see"},{"from":1791.03,"to":1796.68,"location":2,"content":"a bigger spread of the sentence without having many parameters."},{"from":1796.68,"to":1799.07,"location":2,"content":"So you don't have to do things this way."},{"from":1799.07,"to":1800.67,"location":2,"content":"You could have said, look,"},{"from":1800.67,"to":1807.02,"location":2,"content":"I could just instead have convolutions with a kernel size of five."},{"from":1807.02,"to":1808.47,"location":2,"content":"And then they'd say five,"},{"from":1808.47,"to":1811.5,"location":2,"content":"see five words in a row but then I'd be having"},{"from":1811.5,"to":1817.23,"location":2,"content":"sort of bigger matrices to specify my feature."},{"from":1817.23,"to":1820.77,"location":2,"content":"Whereas, this way I can keep the matrices small but still"},{"from":1820.77,"to":1825.11,"location":2,"content":"see a bigger range of the sentence in one operation."},{"from":1825.11,"to":1830.67,"location":2,"content":"Yeah and that concept of how much of a sentence you"},{"from":1830.67,"to":1836.49,"location":2,"content":"see is kind of an important notion in convolutional neural networks."},{"from":1836.49,"to":1839.94,"location":2,"content":"Because, you know, if you start at the beginning of a sentence"},{"from":1839.94,"to":1843.78,"location":2,"content":"and you're just running three-by-three convolutions, um,"},{"from":1843.78,"to":1847.99,"location":2,"content":"you're sort of seeing these three word patches of the sentence."},{"from":1847.99,"to":1850.35,"location":2,"content":"And it turns out in natural language that's"},{"from":1850.35,"to":1853.31,"location":2,"content":"already actually quite a useful representation."},{"from":1853.31,"to":1856.92,"location":2,"content":"Because sort of having those kind of n-grams as features is"},{"from":1856.92,"to":1861.16,"location":2,"content":"just good for many purposes including text classification."},{"from":1861.16,"to":1865.68,"location":2,"content":"But if you want to sort of understand more of the semantics of a sentence,"},{"from":1865.68,"to":1868.58,"location":2,"content":"somehow you wanna see more of that at once."},{"from":1868.58,"to":1873.78,"location":2,"content":"And you've sort of got several tools you can use to see more of it once,"},{"from":1873.78,"to":1875.73,"location":2,"content":"you can use bigger filters,"},{"from":1875.73,"to":1876.87,"location":2,"content":"you could use, uh,"},{"from":1876.87,"to":1878.46,"location":2,"content":"kernel size five, seven,"},{"from":1878.46,"to":1880.65,"location":2,"content":"nine or something convolution."},{"from":1880.65,"to":1885.59,"location":2,"content":"You could do something like dilated convolution so you can see spread out pictures."},{"from":1885.59,"to":1888.12,"location":2,"content":"And the third thing that you can do is you"},{"from":1888.12,"to":1890.84,"location":2,"content":"can have depth of a convolutional neural network."},{"from":1890.84,"to":1895.61,"location":2,"content":"Because as you have greater depth of a convolutional neural network, you see more."},{"from":1895.61,"to":1897.69,"location":2,"content":"So at this first layer,"},{"from":1897.69,"to":1903.15,"location":2,"content":"the rows now have sort of info about three words in them."},{"from":1903.15,"to":1906.63,"location":2,"content":"And if you sort of just stuck a second layer of"},{"from":1906.63,"to":1908.28,"location":2,"content":"convolutional neural network with"},{"from":1908.28,"to":1911.67,"location":2,"content":"the same general nature on top of it and you sort of take"},{"from":1911.67,"to":1915.45,"location":2,"content":"the first three rows and convolve it again then and"},{"from":1915.45,"to":1920.94,"location":2,"content":"then the next ones that those then know about five words of your original input sentence."},{"from":1920.94,"to":1923.7,"location":2,"content":"So as you kind of have a deeper ConvNet stack you"},{"from":1923.7,"to":1927.49,"location":2,"content":"start to know about bigger and bigger patches of the sentence."},{"from":1927.49,"to":1929.97,"location":2,"content":"Okay. All good?"},{"from":1929.97,"to":1934.76,"location":2,"content":"Any questions?"},{"from":1934.76,"to":1942.9,"location":2,"content":"No, that's good, okay. So, um, the next piece is essentially shows you this stuff again,"},{"from":1942.9,"to":1946.56,"location":2,"content":"um, in the context of a particular paper."},{"from":1946.56,"to":1947.85,"location":2,"content":"So this was, um,"},{"from":1947.85,"to":1952.13,"location":2,"content":"a paper by Yoon Kim who was a Harvard student,"},{"from":1952.13,"to":1956.46,"location":2,"content":"maybe still is a Harvard student, um, in 2014."},{"from":1956.46,"to":1959.79,"location":2,"content":"So this was sort of a fairly early paper."},{"from":1959.79,"to":1965.52,"location":2,"content":"Um, and he wanted to show that you could use convolutional neural networks to do"},{"from":1965.52,"to":1967.5,"location":2,"content":"a good job for doing"},{"from":1967.5,"to":1972.24,"location":2,"content":"text classification when what you want to classify is a single sentence."},{"from":1972.24,"to":1975.75,"location":2,"content":"So, the kind of thing you might want to do is look at the kind of"},{"from":1975.75,"to":1980.4,"location":2,"content":"snippets of movie reviews that you see on the Rotten Tomatoes site and say,"},{"from":1980.4,"to":1984.9,"location":2,"content":"\"Is this a positive or is this a negative sentence description?\""},{"from":1984.9,"to":1988.15,"location":2,"content":"And the model he built is actually kind of similar"},{"from":1988.15,"to":1991.69,"location":2,"content":"to the convolutional neural networks that Collobert and Weston,"},{"from":1991.69,"to":1994.98,"location":2,"content":"um, introduced in their 2011 paper that we"},{"from":1994.98,"to":1998.1,"location":2,"content":"mentioned before when we were talking about window-based classifiers."},{"from":1998.1,"to":2000.5,"location":2,"content":"So, in their paper they actually use"},{"from":2000.5,"to":2005.6,"location":2,"content":"both window-based classifiers and the convolutional classifier."},{"from":2005.6,"to":2008.57,"location":2,"content":"Okay. Um, so yeah,"},{"from":2008.57,"to":2009.8,"location":2,"content":"I sort of already said this."},{"from":2009.8,"to":2014.21,"location":2,"content":"So their tasks are sentence classification, could be sentiment."},{"from":2014.21,"to":2015.88,"location":2,"content":"It could be other things like,"},{"from":2015.88,"to":2019.1,"location":2,"content":"is this sentence subjective or objective?"},{"from":2019.1,"to":2022.04,"location":2,"content":"So objective is what the main news articles are meant"},{"from":2022.04,"to":2025.3,"location":2,"content":"to be and subjective is what the opinion pieces are meant to be."},{"from":2025.3,"to":2028.97,"location":2,"content":"Um, and then other things like question classification."},{"from":2028.97,"to":2031.22,"location":2,"content":"Is this a question asking about a person,"},{"from":2031.22,"to":2033.2,"location":2,"content":"location, number, or whatever?"},{"from":2033.2,"to":2037.4,"location":2,"content":"Okay, so here is what he did."},{"from":2037.4,"to":2041.49,"location":2,"content":"And it's sort of the- these slides sort of, um,"},{"from":2041.49,"to":2046.88,"location":2,"content":"use the notation of his paper which is sort of a little bit different the"},{"from":2046.88,"to":2049.31,"location":2,"content":"way the math gets written down to what I just showed"},{"from":2049.31,"to":2052.16,"location":2,"content":"you, that it's really doing exactly the same thing."},{"from":2052.16,"to":2056.93,"location":2,"content":"So we start with word vectors of length k. Um,"},{"from":2056.93,"to":2064.61,"location":2,"content":"the sentence is made by just concatenating all of those word vectors together and then,"},{"from":2064.61,"to":2067.28,"location":2,"content":"when we- so we have a range of words,"},{"from":2067.28,"to":2070.19,"location":2,"content":"it's a subpart of that sentence vector."},{"from":2070.19,"to":2076.31,"location":2,"content":"And so, the convolutional filter is just being represented as a vector because"},{"from":2076.31,"to":2082.1,"location":2,"content":"here he's flattened everything out into one long vector for the entire sentence,"},{"from":2082.1,"to":2084.51,"location":2,"content":"whereas I'd sort of stepped into a matrix."},{"from":2084.51,"to":2091.07,"location":2,"content":"Um, so a size three convolution is just a real vector of length hk,"},{"from":2091.07,"to":2096.35,"location":2,"content":"the size of the convolutional filter times the dimensionality of the words."},{"from":2096.35,"to":2101.21,"location":2,"content":"Um, and so, what he's gonna do to build"},{"from":2101.21,"to":2107.45,"location":2,"content":"his text classifier is use convolutions made out of different sizes."},{"from":2107.45,"to":2110.76,"location":2,"content":"So you can have size two convolutions,"},{"from":2110.76,"to":2116,"location":2,"content":"size three convolutions as shown here, and bigger convolutions."},{"from":2116,"to":2123.14,"location":2,"content":"And so, um, so to compute a feature one channel for our CNN, we're"},{"from":2123.14,"to":2126.62,"location":2,"content":"then doing a dot product between the weight vector of"},{"from":2126.62,"to":2130.41,"location":2,"content":"the feature times this sub-sequence of the same terms,"},{"from":2130.41,"to":2135.03,"location":2,"content":"and he sort of also put in a bias which I sort of omitted."},{"from":2135.03,"to":2141.11,"location":2,"content":"Um, and then putting it through a non-linearity,"},{"from":2141.11,"to":2143.39,"location":2,"content":"um, which I wasn't doing either."},{"from":2143.39,"to":2146.05,"location":2,"content":"Um, but as sort of we've seen a ton of."},{"from":2146.05,"to":2149.81,"location":2,"content":"Um, and so, what we're wanting to do is that's our,"},{"from":2149.81,"to":2153.41,"location":2,"content":"um, feature and we want to, um,"},{"from":2153.41,"to":2158.15,"location":2,"content":"do it through all this- for a feature of kernel size three,"},{"from":2158.15,"to":2160.88,"location":2,"content":"we're gonna go all the way through the sentence."},{"from":2160.88,"to":2164.74,"location":2,"content":"The other thing he did though was slightly funnel funny is,"},{"from":2164.74,"to":2168.92,"location":2,"content":"his windows were sort of lopsided in the notation, right."},{"from":2168.92,"to":2171.7,"location":2,"content":"There's a word and th- the,"},{"from":2171.7,"to":2175.36,"location":2,"content":"um, h minus 1 words to the right of it."},{"from":2175.36,"to":2180.09,"location":2,"content":"So he has padding here just on the right end whereas"},{"from":2180.09,"to":2185.81,"location":2,"content":"most people do their convolutions symmetrically in both directions around things."},{"from":2185.81,"to":2191.63,"location":2,"content":"Okay. And so, we're going to do that for a bunch of features or"},{"from":2191.63,"to":2194.48,"location":2,"content":"channels Ci and therefore compute"},{"from":2194.48,"to":2198.68,"location":2,"content":"our convolved representations just as we've talked about."},{"from":2198.68,"to":2203.43,"location":2,"content":"Okay. Um, then he does just what we talked about."},{"from":2203.43,"to":2208.37,"location":2,"content":"Um, there's max over time pooling in the pooling layer to capture"},{"from":2208.37,"to":2213.65,"location":2,"content":"the most relevant things and is giving us a single number for each channel."},{"from":2213.65,"to":2221.47,"location":2,"content":"Um, and we have features that look at different that have different kernel sizes."},{"from":2221.47,"to":2228.23,"location":2,"content":"Um, here's one other idea he used which is possibly a neat idea."},{"from":2228.23,"to":2233.66,"location":2,"content":"Um, he knows one of the things that you could even think about in various ways,"},{"from":2233.66,"to":2237.35,"location":2,"content":"um, for say a question answering system among other things."},{"from":2237.35,"to":2241.61,"location":2,"content":"Um, and so he used pre-trained word vectors."},{"from":2241.61,"to":2248.98,"location":2,"content":"Um, but what he did was he actually kind of doubled the word vectors."},{"from":2248.98,"to":2252.47,"location":2,"content":"So, for each word he had two copies of the word vector,"},{"from":2252.47,"to":2257.29,"location":2,"content":"and so you have sort of two channel sets and one set he"},{"from":2257.29,"to":2262.38,"location":2,"content":"froze and the other one he fine tuned as he trained."},{"from":2262.38,"to":2266.59,"location":2,"content":"So it's sort of he tried to get the best of both worlds of sort of fine tuning"},{"from":2266.59,"to":2271.77,"location":2,"content":"and not fine tuning and all that went into the max pooling operation."},{"from":2271.77,"to":2281.61,"location":2,"content":"Okay. Um, so, after the max pooling we get out one number for each channel and so,"},{"from":2281.61,"to":2286.76,"location":2,"content":"um, he has something of three size convolutions, three,"},{"from":2286.76,"to":2290.39,"location":2,"content":"four, five, 100 features for each size."},{"from":2290.39,"to":2293.43,"location":2,"content":"So we're getting out a vector of size,"},{"from":2293.43,"to":2295.67,"location":2,"content":"um, 300 at that point,"},{"from":2295.67,"to":2299.81,"location":2,"content":"and at that point you're taking that final vector and just sticking it"},{"from":2299.81,"to":2304.59,"location":2,"content":"through a softmax and that's then giving your classification of the classes."},{"from":2304.59,"to":2311.49,"location":2,"content":"Um, so all of that can be summarized in this picture if it's big enough to sort of read."},{"from":2311.49,"to":2312.8,"location":2,"content":"So, here's our sentence."},{"from":2312.8,"to":2314.86,"location":2,"content":"I like this movie very much,"},{"from":2314.86,"to":2319.31,"location":2,"content":"which has you know, our word embedding dimension is five,"},{"from":2319.31,"to":2322.26,"location":2,"content":"and so then doing it in this example,"},{"from":2322.26,"to":2326.93,"location":2,"content":"we are having two channels for each kernel size and"},{"from":2326.93,"to":2332.03,"location":2,"content":"we consider kernels of size two, three, and four."},{"from":2332.03,"to":2337.2,"location":2,"content":"Um, and so and then we are getting two different ones."},{"from":2337.2,"to":2341.61,"location":2,"content":"Um, so we're getting, um, six."},{"from":2341.61,"to":2344.41,"location":2,"content":"This is showing six of our filters."},{"from":2344.41,"to":2347.18,"location":2,"content":"Um, so we apply those."},{"from":2347.18,"to":2350.97,"location":2,"content":"When we- when we apply those filters without any padding,"},{"from":2350.97,"to":2355.88,"location":2,"content":"we are then getting out these outputs of the filters which are of sizes four,"},{"from":2355.88,"to":2358.99,"location":2,"content":"five, and six respectively."},{"from":2358.99,"to":2363.07,"location":2,"content":"Um, and so then once we've got these"},{"from":2363.07,"to":2367.26,"location":2,"content":"for each of these sets of numbers we're doing one max pooling."},{"from":2367.26,"to":2370.88,"location":2,"content":"So, we're just taking the max of each of these,"},{"from":2370.88,"to":2376.72,"location":2,"content":"um, output features which gives us these six numbers."},{"from":2376.72,"to":2383.06,"location":2,"content":"Um, we can concatenate them all together into one vector which we feed into,"},{"from":2383.06,"to":2392.58,"location":2,"content":"um, a softmax over two classes as to whether sentiment is positive or negative."},{"from":2392.58,"to":2395.59,"location":2,"content":"Um, so that's basically the model."},{"from":2395.59,"to":2401.2,"location":2,"content":"So something- so this is sort of really actually a very simple,"},{"from":2401.2,"to":2403.63,"location":2,"content":"very computationally efficient, uh,"},{"from":2403.63,"to":2406.78,"location":2,"content":"model as to how to build a text classifier."},{"from":2406.78,"to":2413.16,"location":2,"content":"[NOISE] Um, yeah, just a couple more things to get through,"},{"from":2413.16,"to":2415.21,"location":2,"content":"um, so in one of the assignments,"},{"from":2415.21,"to":2417.7,"location":2,"content":"we talked about Dropout [NOISE] and you used it."},{"from":2417.7,"to":2419.07,"location":2,"content":"So, um, you know,"},{"from":2419.07,"to":2421.7,"location":2,"content":"hopefully you're all masters of Dropout at this point."},{"from":2421.7,"to":2424.72,"location":2,"content":"Um, so he was using Dropout, um,"},{"from":2424.72,"to":2428.18,"location":2,"content":"and this being 2014 and the,"},{"from":2428.18,"to":2431.82,"location":2,"content":"um, Dropout paper only coming out in 2014."},{"from":2431.82,"to":2434.89,"location":2,"content":"I guess, there'd been an earlier version that came out a couple of years earlier."},{"from":2434.89,"to":2437.16,"location":2,"content":"This was sort of still fairly early,"},{"from":2437.16,"to":2439.43,"location":2,"content":"um, to be taking advantage of Dropout."},{"from":2439.43,"to":2441.14,"location":2,"content":"So that while training,"},{"from":2441.14,"to":2444.11,"location":2,"content":"you've got this sort of Dropout vector, um,"},{"from":2444.11,"to":2449.01,"location":2,"content":"where you sample your Bernoulli random variables and you're, sort of,"},{"from":2449.01,"to":2454.82,"location":2,"content":"um, sort of, designed to drop out some of the features each time you are doing things."},{"from":2454.82,"to":2458.2,"location":2,"content":"At testing time, you don't do the dropout,"},{"from":2458.2,"to":2462.13,"location":2,"content":"but because before you were sort of dropping out a lot of stuff,"},{"from":2462.13,"to":2467.45,"location":2,"content":"you're scaling your weight matrix by the same probability that you use for dropping out,"},{"from":2467.45,"to":2469,"location":2,"content":"so that you get, sort of,"},{"from":2469,"to":2472,"location":2,"content":"vectors of the same scale as before."},{"from":2472,"to":2475.07,"location":2,"content":"Um, so as we sort of discussed in the assignment,"},{"from":2475.07,"to":2478.42,"location":2,"content":"Dropout is a really effective form of regularization,"},{"from":2478.42,"to":2480.58,"location":2,"content":"widely used in neural networks."},{"from":2480.58,"to":2483.7,"location":2,"content":"Um, he didn't only do that, he actually did,"},{"from":2483.7,"to":2487.6,"location":2,"content":"a kind of another sort of funky form of regularization."},{"from":2487.6,"to":2491.43,"location":2,"content":"So that's for the softmax weight vector,"},{"from":2491.43,"to":2495.28,"location":2,"content":"he constrained the L2 norms,"},{"from":2495.28,"to":2501.1,"location":2,"content":"so the squared norms of the weight vectors and the softmax, [NOISE] um,"},{"from":2501.1,"to":2505.41,"location":2,"content":"matrix, um, to a fixed number S,"},{"from":2505.41,"to":2507.46,"location":2,"content":"which was sort of set of the hyper-parameters,"},{"from":2507.46,"to":2509.51,"location":2,"content":"actually set to the value three."},{"from":2509.51,"to":2513.05,"location":2,"content":"Um, and if your weights were getting too large,"},{"from":2513.05,"to":2515.59,"location":2,"content":"they were being rescaled,"},{"from":2515.59,"to":2517.34,"location":2,"content":"um, so they didn't blow up."},{"from":2517.34,"to":2520.21,"location":2,"content":"Um, this isn't a very common thing to do."},{"from":2520.21,"to":2523.69,"location":2,"content":"I'm not sure it's very necessary, um, but, um,"},{"from":2523.69,"to":2525.85,"location":2,"content":"I guess it gives you some- I mean,"},{"from":2525.85,"to":2529.05,"location":2,"content":"I guess by showing you a few of the details of this one,"},{"from":2529.05,"to":2530.59,"location":2,"content":"my hope is, sort of,"},{"from":2530.59,"to":2533.68,"location":2,"content":"gives you some ideas about how there are lots of things you can play"},{"from":2533.68,"to":2537.03,"location":2,"content":"around with and muck with if you wanna try different things,"},{"from":2537.03,"to":2539.02,"location":2,"content":"um, for your final projects."},{"from":2539.02,"to":2541,"location":2,"content":"Um, okay."},{"from":2541,"to":2544.12,"location":2,"content":"So here are some of his final hyperparameters."},{"from":2544.12,"to":2547.36,"location":2,"content":"So he's using ReLU nonlinearities,"},{"from":2547.36,"to":2550.76,"location":2,"content":"um, window sizes of three, four, and five,"},{"from":2550.76,"to":2555.79,"location":2,"content":"the convolutions, hundred features or channels for each size,"},{"from":2555.79,"to":2558.53,"location":2,"content":"um, Dropout of a half as usual."},{"from":2558.53,"to":2561.86,"location":2,"content":"Um, you get several percentage improvements from dropout,"},{"from":2561.86,"to":2563.86,"location":2,"content":"which is quite common actually."},{"from":2563.86,"to":2567.84,"location":2,"content":"Um, the sort of L2 constraint, s equals three,"},{"from":2567.84,"to":2570.18,"location":2,"content":"mini batch of 50,"},{"from":2570.18,"to":2572.64,"location":2,"content":"300 dimensional word vectors,"},{"from":2572.64,"to":2575.76,"location":2,"content":"train to maximize dev set performance."},{"from":2575.76,"to":2578.83,"location":2,"content":"Okay. And here is the big table,"},{"from":2578.83,"to":2580.69,"location":2,"content":"you know, I was too lazy, um,"},{"from":2580.69,"to":2586.57,"location":2,"content":"to redo of performance on these different text classification data sets."},{"from":2586.57,"to":2588.46,"location":2,"content":"Um, there are lots of different ones."},{"from":2588.46,"to":2591.82,"location":2,"content":"So these two are both Stanford Sentiment Treebank."},{"from":2591.82,"to":2594.57,"location":2,"content":"This is the Subjective Objective Language."},{"from":2594.57,"to":2599.65,"location":2,"content":"This is the Question Classification, of is it asking for a person name and location,"},{"from":2599.65,"to":2600.79,"location":2,"content":"a company or whatever."},{"from":2600.79,"to":2604.15,"location":2,"content":"Um, this is, um,"},{"from":2604.15,"to":2606.28,"location":2,"content":"talking about, sort of, a perspective,"},{"from":2606.28,"to":2608.34,"location":2,"content":"which is another classification thing."},{"from":2608.34,"to":2610.89,"location":2,"content":"Consumer Reports is another sentiment one."},{"from":2610.89,"to":2616.21,"location":2,"content":"Um, so lots of data sets and then here are lots of models."},{"from":2616.21,"to":2621.58,"location":2,"content":"So the model- some of the models down here or here,"},{"from":2621.58,"to":2626.02,"location":2,"content":"are traditional feature-based, um, classifiers."},{"from":2626.02,"to":2628,"location":2,"content":"Um, so in particular,"},{"from":2628,"to":2632.23,"location":2,"content":"um, sort of Wang and me back in 2012,"},{"from":2632.23,"to":2636.03,"location":2,"content":"had sort of pointed out that by taking certain steps"},{"from":2636.03,"to":2640.72,"location":2,"content":"with n-gram features and other forms of normalization,"},{"from":2640.72,"to":2643.42,"location":2,"content":"that you could actually get quite good results with"},{"from":2643.42,"to":2646.96,"location":2,"content":"just the traditional feature, um, based classifiers."},{"from":2646.96,"to":2652.05,"location":2,"content":"So many people use that as a baseline for showing that you can do better things."},{"from":2652.05,"to":2654.36,"location":2,"content":"Um, the ones up here,"},{"from":2654.36,"to":2658.2,"location":2,"content":"were tree structured neural networks that my group was very fond"},{"from":2658.2,"to":2662.8,"location":2,"content":"of in the early 2010s and then up at the very top,"},{"from":2662.8,"to":2664.7,"location":2,"content":"uh, his CNN models."},{"from":2664.7,"to":2666.51,"location":2,"content":"And as you can see,"},{"from":2666.51,"to":2667.88,"location":2,"content":"it's sort of a mix."},{"from":2667.88,"to":2670.87,"location":2,"content":"Sometimes the CNN model wins,"},{"from":2670.87,"to":2673.01,"location":2,"content":"like in this column and this column,"},{"from":2673.01,"to":2676.01,"location":2,"content":"sometimes it doesn't win like in these columns."},{"from":2676.01,"to":2678.01,"location":2,"content":"Um, but in general, um,"},{"from":2678.01,"to":2680.26,"location":2,"content":"what you didn't see from this is that, you know,"},{"from":2680.26,"to":2683.14,"location":2,"content":"this is an extremely simple, um,"},{"from":2683.14,"to":2686.34,"location":2,"content":"convolutional neural network model and it actually does,"},{"from":2686.34,"to":2688.72,"location":2,"content":"um, kind of well on this system."},{"from":2688.72,"to":2694.72,"location":2,"content":"Um, you can quibble with this results table,"},{"from":2694.72,"to":2701.28,"location":2,"content":"and again in terms of like writing your propos- project proposal, um,"},{"from":2701.28,"to":2707.25,"location":2,"content":"one thing that you should do is kind of think about what you're reading, um,"},{"from":2707.25,"to":2710.1,"location":2,"content":"because, you know, a lot of papers aren't perfect"},{"from":2710.1,"to":2713.13,"location":2,"content":"and there are reasons to quibble with what they claim."},{"from":2713.13,"to":2717.78,"location":2,"content":"And sometimes if you think about what they're claiming and whether it's reasonable, um,"},{"from":2717.78,"to":2720.89,"location":2,"content":"there are reasons why it's not or there are ideas"},{"from":2720.89,"to":2724.41,"location":2,"content":"of how you could do things differently or show something different."},{"from":2724.41,"to":2727.32,"location":2,"content":"I mean, the main reason why you could quibble with,"},{"from":2727.32,"to":2731.36,"location":2,"content":"um, Yoon Kim's results table is, well,"},{"from":2731.36,"to":2735.39,"location":2,"content":"he already said, as I had a couple of slides back, um,"},{"from":2735.39,"to":2737.98,"location":2,"content":"that the statement that Dropout gives you"},{"from":2737.98,"to":2741.22,"location":2,"content":"two to four percent accuracy improvement in this neural nets."},{"from":2741.22,"to":2745.21,"location":2,"content":"[NOISE] Um, but most of these systems because they"},{"from":2745.21,"to":2749.36,"location":2,"content":"are older and were done before Dropout was invented,"},{"from":2749.36,"to":2751.39,"location":2,"content":"um, didn't make use of Dropout."},{"from":2751.39,"to":2755.17,"location":2,"content":"But, you know, any of these sort of neural net systems up here"},{"from":2755.17,"to":2759.45,"location":2,"content":"could have used Dropout and presumably it would have given them a couple of,"},{"from":2759.45,"to":2761.14,"location":2,"content":"um, percent gain as well."},{"from":2761.14,"to":2765.39,"location":2,"content":"So arguably, this is sort of a biased, unfair comparison."},{"from":2765.39,"to":2770.64,"location":2,"content":"And the right thing would have been to be comparing all the systems, um, using Dropout."},{"from":2770.64,"to":2772.12,"location":2,"content":"Um, but, you know,"},{"from":2772.12,"to":2773.89,"location":2,"content":"despite that, you know,"},{"from":2773.89,"to":2776.98,"location":2,"content":"this was still a prett- a lot of people noticed"},{"from":2776.98,"to":2780.82,"location":2,"content":"this paper because it showed that using this sort of very simple,"},{"from":2780.82,"to":2783.19,"location":2,"content":"very fast convolutional architecture,"},{"from":2783.19,"to":2788.25,"location":2,"content":"could give you strong results for text classification."},{"from":2788.25,"to":2791.01,"location":2,"content":"Um, that's that."},{"from":2791.01,"to":2793.76,"location":2,"content":"Yes. So in summary,"},{"from":2793.76,"to":2798.47,"location":2,"content":"you know, something that you should be thinking about for projects and otherwise,"},{"from":2798.47,"to":2804.37,"location":2,"content":"we're effectively building up a bigger toolkit of different tools you could be using,"},{"from":2804.37,"to":2808.14,"location":2,"content":"um, for projects or future work or whatever it is."},{"from":2808.14,"to":2809.64,"location":2,"content":"So starting off with,"},{"from":2809.64,"to":2813.25,"location":2,"content":"we had word vectors and then we could build bag of"},{"from":2813.25,"to":2817.11,"location":2,"content":"vector models by just taking the word vectors and averaging them."},{"from":2817.11,"to":2821.08,"location":2,"content":"And, you know, that's actually a surprisingly good baseline to start with."},{"from":2821.08,"to":2823.96,"location":2,"content":"We suggest to you in many cases for things like projects,"},{"from":2823.96,"to":2825.09,"location":2,"content":"you should use that."},{"from":2825.09,"to":2826.27,"location":2,"content":"See how well it does,"},{"from":2826.27,"to":2827.97,"location":2,"content":"make sure you're working better."},{"from":2827.97,"to":2830.61,"location":2,"content":"I mean particularly, you can do even better with that,"},{"from":2830.61,"to":2834.49,"location":2,"content":"if you sort of add some extra ReLU layers on top,"},{"from":2834.49,"to":2838.01,"location":2,"content":"which is an idea that's been explored in deep averaging networks."},{"from":2838.01,"to":2842.29,"location":2,"content":"Um, then we looked at window models which were very simple."},{"from":2842.29,"to":2843.85,"location":2,"content":"You're just taking these sort of"},{"from":2843.85,"to":2847.59,"location":2,"content":"five word windows and computing a feed-forward network on them,"},{"from":2847.59,"to":2852.84,"location":2,"content":"and they work very well for word classification problems that only need local context."},{"from":2852.84,"to":2856.05,"location":2,"content":"Things like, part of speech tagging or NER."},{"from":2856.05,"to":2859.39,"location":2,"content":"But then we've gone ahead and looked at some other models."},{"from":2859.39,"to":2865.41,"location":2,"content":"And so, um, CNN's are very good for text classification, um,"},{"from":2865.41,"to":2869.59,"location":2,"content":"and they're very good because they parallelize really well on GPUs,"},{"from":2869.59,"to":2871.84,"location":2,"content":"which is something I'll come back to again later."},{"from":2871.84,"to":2877.51,"location":2,"content":"So they, they just sort- the general sort of representing sentence meaning."},{"from":2877.51,"to":2879.1,"location":2,"content":"They're actually a efficient,"},{"from":2879.1,"to":2882.3,"location":2,"content":"versatile, good method, which has been used quite a bit."},{"from":2882.3,"to":2885.46,"location":2,"content":"And then they sort of contrast with recurrent neural networks."},{"from":2885.46,"to":2887.8,"location":2,"content":"Recurrent neural networks have some advantages."},{"from":2887.8,"to":2890.08,"location":2,"content":"They're sort of more cognitively plausible,"},{"from":2890.08,"to":2892.12,"location":2,"content":"because you're sort of reading through the text and,"},{"from":2892.12,"to":2894.14,"location":2,"content":"um, getting its meaning."},{"from":2894.14,"to":2896.83,"location":2,"content":"Um, recurrent neural networks are good for"},{"from":2896.83,"to":2899.8,"location":2,"content":"things like sequence tagging and classification,"},{"from":2899.8,"to":2903.39,"location":2,"content":"building language models to predict what's coming next."},{"from":2903.39,"to":2906.91,"location":2,"content":"Um, they can do really well when combined with attention."},{"from":2906.91,"to":2909.57,"location":2,"content":"Um, but they also have some disadvantages."},{"from":2909.57,"to":2913.87,"location":2,"content":"They're way slower than convolutional neural networks and if what you wanna"},{"from":2913.87,"to":2918.3,"location":2,"content":"do is get out some kind of overall meaning representation of a sentence,"},{"from":2918.3,"to":2919.84,"location":2,"content":"you know, \"What does this mean?"},{"from":2919.84,"to":2921.38,"location":2,"content":"Are these two, um,"},{"from":2921.38,"to":2923.85,"location":2,"content":"phrases paraphrases with each other?\""},{"from":2923.85,"to":2926.73,"location":2,"content":"There are now many results that show that people"},{"from":2926.73,"to":2929.8,"location":2,"content":"don't get better results with recurrent neural networks."},{"from":2929.8,"to":2935.55,"location":2,"content":"They can get better results using techniques like convolutional neural networks."},{"from":2935.55,"to":2945.01,"location":2,"content":"Okay. [NOISE] So in the next step then [NOISE] is to,"},{"from":2945.01,"to":2949.68,"location":2,"content":"sort of, head towards our com- our complex,"},{"from":2949.68,"to":2952.38,"location":2,"content":"um, convolutional architecture example."},{"from":2952.38,"to":2954.01,"location":2,"content":"So before getting to that,"},{"from":2954.01,"to":2958.53,"location":2,"content":"I just wanna sort of introduce a few concepts that we haven't seen,"},{"from":2958.53,"to":2962.63,"location":2,"content":"all of which, um, start to turn up when we do this."},{"from":2962.63,"to":2966.36,"location":2,"content":"So we spent a lot of time in the sequence models part,"},{"from":2966.36,"to":2972.34,"location":2,"content":"talking about gated models or the gated recurrent units and the LSTM units."},{"from":2972.34,"to":2976.08,"location":2,"content":"But the idea of a gate is general that we can"},{"from":2976.08,"to":2980.13,"location":2,"content":"sort of have this idea that we can calculate something,"},{"from":2980.13,"to":2982.18,"location":2,"content":"put it through, um,"},{"from":2982.18,"to":2987.37,"location":2,"content":"a sigmoid nonlinearity and gets a value between zero and one,"},{"from":2987.37,"to":2990.39,"location":2,"content":"um, or a vector of values between zero and one."},{"from":2990.39,"to":2992.98,"location":2,"content":"And then do a Hadamard product with a vector"},{"from":2992.98,"to":2995.86,"location":2,"content":"and sort of gate it between its value and zero."},{"from":2995.86,"to":2999.49,"location":2,"content":"So that suggests the idea that you could also apply"},{"from":2999.49,"to":3004.11,"location":2,"content":"gates vertically when you're building multilayer networks."},{"from":3004.11,"to":3007.84,"location":2,"content":"And after the successive LSTMs had been proven,"},{"from":3007.84,"to":3011.78,"location":2,"content":"that was, um, an idea that really took off,"},{"from":3011.78,"to":3013.73,"location":2,"content":"was people start exploring,"},{"from":3013.73,"to":3019.45,"location":2,"content":"how can we have, use these ideas of skip connections and gating in a,"},{"from":3019.45,"to":3021.43,"location":2,"content":"in a vertical direction?"},{"from":3021.43,"to":3023.48,"location":2,"content":"And here are two versions of it."},{"from":3023.48,"to":3026.45,"location":2,"content":"This one is a very simple one,"},{"from":3026.45,"to":3030.97,"location":2,"content":"but a very successful one that's basically just about a skip connection."},{"from":3030.97,"to":3036.89,"location":2,"content":"So and this is referred to as a residual block and- which is used in residual networks,"},{"from":3036.89,"to":3038.69,"location":2,"content":"otherwise known as ResNets."},{"from":3038.69,"to":3042.47,"location":2,"content":"Um, so in a residual block, for each block,"},{"from":3042.47,"to":3048.44,"location":2,"content":"you allow a value just to skip ahead to the next, um, layer."},{"from":3048.44,"to":3052.53,"location":2,"content":"Or you can stick it through a conv block,"},{"from":3052.53,"to":3056.82,"location":2,"content":"and the typical conv block is you go through a convolutional layer,"},{"from":3056.82,"to":3059.6,"location":2,"content":"you then go through a ReLU nonlinearity,"},{"from":3059.6,"to":3063.25,"location":2,"content":"another convolutional layer, and then when you come out,"},{"from":3063.25,"to":3065.43,"location":2,"content":"you just sum these two values."},{"from":3065.43,"to":3067.71,"location":2,"content":"So this is the same idea that sort of"},{"from":3067.71,"to":3071.82,"location":2,"content":"summing values is magical in the same way as an LSTM."},{"from":3071.82,"to":3075.16,"location":2,"content":"And then you put the output of that through another ReLU,"},{"from":3075.16,"to":3078.7,"location":2,"content":"and this thing here is called a residual block"},{"from":3078.7,"to":3082.95,"location":2,"content":"and then commonly you'll stack residual blocks on top of each other."},{"from":3082.95,"to":3085.23,"location":2,"content":"Um, there's one little trick here,"},{"from":3085.23,"to":3088.32,"location":2,"content":"um, which is you need to use padding, right?"},{"from":3088.32,"to":3093,"location":2,"content":"Um, because at the end of the day since you want to sum these two pathways,"},{"from":3093,"to":3095.36,"location":2,"content":"you want them to be the same size."},{"from":3095.36,"to":3096.59,"location":2,"content":"And if you, sort of,"},{"from":3096.59,"to":3100.2,"location":2,"content":"have them shrinking in the conv blocks you wouldn't be able to sum them."},{"from":3100.2,"to":3105.12,"location":2,"content":"So you want to, sort of, have a padding at each stage so they stay the same size here,"},{"from":3105.12,"to":3107.44,"location":2,"content":"and so that you can add them together."},{"from":3107.44,"to":3114.5,"location":2,"content":"Um, here's, um, a different version of a block which is"},{"from":3114.5,"to":3117.47,"location":2,"content":"sort of more LSTM-ish and indeed"},{"from":3117.47,"to":3121.71,"location":2,"content":"this block was developed by Jürgen Schmidhuber and students,"},{"from":3121.71,"to":3126,"location":2,"content":"who's the same guy who's behind LSTMs and you can see the same thinking."},{"from":3126,"to":3128.15,"location":2,"content":"It's called a highway block."},{"from":3128.15,"to":3130.8,"location":2,"content":"So in a way it's sort of similar."},{"from":3130.8,"to":3136.08,"location":2,"content":"You've got, you know, kind of thinking of moving an identity x that skips"},{"from":3136.08,"to":3143.09,"location":2,"content":"a nonlinear block or you can have it go through exactly the same stuff conv, relu, conv."},{"from":3143.09,"to":3146.48,"location":2,"content":"The difference is that unlike this one,"},{"from":3146.48,"to":3149.16,"location":2,"content":"this time there's explicit gates so there's,"},{"from":3149.16,"to":3153.29,"location":2,"content":"um, and this T-gate and the C-gate."},{"from":3153.29,"to":3159.23,"location":2,"content":"And so you're multiplying both of the path through here and the path through here"},{"from":3159.23,"to":3162.28,"location":2,"content":"by a gate just kinda like the sort of"},{"from":3162.28,"to":3167.13,"location":2,"content":"the get input gates that we saw before and then summing them together."},{"from":3167.13,"to":3170.67,"location":2,"content":"So that sort of feels more"},{"from":3170.67,"to":3176.28,"location":2,"content":"powerful but it's not actually clear that it is more powerful."},{"from":3176.28,"to":3179.46,"location":2,"content":"I mean, this one actually has a very simple"},{"from":3179.46,"to":3183.07,"location":2,"content":"semantic because if you think of the semantics of this one"},{"from":3183.07,"to":3185.93,"location":2,"content":"is the default is just you walk"},{"from":3185.93,"to":3191.01,"location":2,"content":"this way and you just sort of carry forward your value and do nothing."},{"from":3191.01,"to":3194.9,"location":2,"content":"Um, so, what this block's job to- is to do,"},{"from":3194.9,"to":3198.16,"location":2,"content":"is to learn a delta that is meant to learn"},{"from":3198.16,"to":3201.75,"location":2,"content":"what kind of deviation you have from doing nothing."},{"from":3201.75,"to":3205.21,"location":2,"content":"Um, so that's a nice simple semantic which, um,"},{"from":3205.21,"to":3208.68,"location":2,"content":"seems to work well in neural networks to learn things."},{"from":3208.68,"to":3211.39,"location":2,"content":"Um, this sort of has"},{"from":3211.39,"to":3216.5,"location":2,"content":"more complicated apparent semantics because you're taking, you know,"},{"from":3216.5,"to":3223.01,"location":2,"content":"some parts of the identity multiplying by this sort of gate in a Hadamard product"},{"from":3223.01,"to":3229.88,"location":2,"content":"and some parts of this conv block multiplied by this other gate T in a Hadamard product."},{"from":3229.88,"to":3233.98,"location":2,"content":"So that sort of feels more powerful as that"},{"from":3233.98,"to":3238.32,"location":2,"content":"gives me a lot more control because I can take pieces of the different ones and so on."},{"from":3238.32,"to":3241.62,"location":2,"content":"If you think about it for a bit longer, I mean,"},{"from":3241.62,"to":3245.38,"location":2,"content":"mathematically it's actually not any more powerful that you"},{"from":3245.38,"to":3249.5,"location":2,"content":"can represent anything you can do with this one with that one."},{"from":3249.5,"to":3253.53,"location":2,"content":"And the way to think about that is well, um,"},{"from":3253.53,"to":3259.41,"location":2,"content":"you know, here you're kind of keeping only part of the identity,"},{"from":3259.41,"to":3266.84,"location":2,"content":"um, but what you could do is keep the whole of the identity and see it as your job"},{"from":3266.84,"to":3270.09,"location":2,"content":"to subtract off the bits that this one isn't keeping"},{"from":3270.09,"to":3274.44,"location":2,"content":"over here in the conv block which you can do theoretically."},{"from":3274.44,"to":3279.48,"location":2,"content":"Um, and so, you can sort of anything you can compute with this as a function,"},{"from":3279.48,"to":3282.83,"location":2,"content":"you can actually compute with a, um, ResNet block."},{"from":3282.83,"to":3287.18,"location":2,"content":"Um, and so then as quite often in neural network land,"},{"from":3287.18,"to":3289.33,"location":2,"content":"the question isn't sort of, um,"},{"from":3289.33,"to":3293.19,"location":2,"content":"some kind of proof of compute- can be computed or not."},{"from":3293.19,"to":3298.45,"location":2,"content":"It sort of comes down to learning and regularization questions as to"},{"from":3298.45,"to":3301.34,"location":2,"content":"whether one or the other of these actually proves"},{"from":3301.34,"to":3306.43,"location":2,"content":"better as something to use in a learning architecture."},{"from":3306.43,"to":3309.68,"location":2,"content":"Okay. Second concept."},{"from":3309.68,"to":3311.86,"location":2,"content":"Um, batch normalization."},{"from":3311.86,"to":3317.41,"location":2,"content":"So when people are building deep convolutional neural networks,"},{"from":3317.41,"to":3321.68,"location":2,"content":"um, in the 2015 pluses,"},{"from":3321.68,"to":3327.07,"location":2,"content":"um, they almost always use batch normalization layers because"},{"from":3327.07,"to":3332.68,"location":2,"content":"this makes your life a lot better and if they're not using batch normalization layers,"},{"from":3332.68,"to":3337.07,"location":2,"content":"they're normally using one of the other variant ideas that people have suggested"},{"from":3337.07,"to":3342.16,"location":2,"content":"such as layer normalization which is sort of meant to do about the same thing."},{"from":3342.16,"to":3346.09,"location":2,"content":"Um, so what batch normalization does?"},{"from":3346.09,"to":3350.65,"location":2,"content":"I mean, I think many of you will have seen somewhere in steps or"},{"from":3350.65,"to":3356.3,"location":2,"content":"otherwise the idea of doing a Z-transform which means you take your data,"},{"from":3356.3,"to":3359.1,"location":2,"content":"you work out its mean and you work out its"},{"from":3359.1,"to":3363.97,"location":2,"content":"standard deviation and then you rescale by subtraction and"},{"from":3363.97,"to":3367.71,"location":2,"content":"multiplication so that you have a set of data which"},{"from":3367.71,"to":3372.36,"location":2,"content":"has a mean of zero and a standard deviation of one."},{"from":3372.36,"to":3374.68,"location":2,"content":"Most people see that, right?"},{"from":3374.68,"to":3383.5,"location":2,"content":"Yeah? Um, so batch normalization is effectively doing exactly that but in a weird way."},{"from":3383.5,"to":3387.77,"location":2,"content":"So what you're doing is that you're taking each mini batch."},{"from":3387.77,"to":3391.88,"location":2,"content":"So whatever just random 32 examples you've stuck in a mini batch,"},{"from":3391.88,"to":3394.04,"location":2,"content":"you're running them through a layer of"},{"from":3394.04,"to":3397.36,"location":2,"content":"your neural network like a ConvBlock that we saw before"},{"from":3397.36,"to":3403.19,"location":2,"content":"and you take the output of that mini batch and then you do a Z-transform on it."},{"from":3403.19,"to":3407.3,"location":2,"content":"Um, and then it goes forward into the next ConvBlock or whatever,"},{"from":3407.3,"to":3409.41,"location":2,"content":"and the next time you have a different mini batch,"},{"from":3409.41,"to":3410.99,"location":2,"content":"you just Z-transform it."},{"from":3410.99,"to":3412.29,"location":2,"content":"So it seems a little bit weird."},{"from":3412.29,"to":3416.6,"location":2,"content":"You're just doing it on the output of these mini batches."},{"from":3416.6,"to":3421.68,"location":2,"content":"Um, but that's proven to be a very effective thing to do."},{"from":3421.68,"to":3425.98,"location":2,"content":"So that it sort of means that what comes out of"},{"from":3425.98,"to":3429.89,"location":2,"content":"a ConvBlock sort of always has the same kind of scale."},{"from":3429.89,"to":3433.72,"location":2,"content":"So it doesn't sort of fluctuate a lot and mess things up and it tends to"},{"from":3433.72,"to":3438.22,"location":2,"content":"make the models just much more reliably trainable because,"},{"from":3438.22,"to":3442.86,"location":2,"content":"you know, you just have to be much less fussy about a lot of things."},{"from":3442.86,"to":3445.51,"location":2,"content":"Because, you know, a lot of the things we've talked about,"},{"from":3445.51,"to":3448.18,"location":2,"content":"about initializing your parameters and"},{"from":3448.18,"to":3451.13,"location":2,"content":"setting your learning rates is sort of about, well,"},{"from":3451.13,"to":3454.31,"location":2,"content":"you have to keep the scale of things about right so they don't get"},{"from":3454.31,"to":3457.81,"location":2,"content":"too big or too small and things like that."},{"from":3457.81,"to":3460.28,"location":2,"content":"Whereas, if you're doing this batch normalization,"},{"from":3460.28,"to":3462.49,"location":2,"content":"you're sort of forcing scale,"},{"from":3462.49,"to":3465.7,"location":2,"content":"um, to being the same size each time."},{"from":3465.7,"to":3468.37,"location":2,"content":"And s o therefore, you kind of don't have to do"},{"from":3468.37,"to":3471.2,"location":2,"content":"the other stuff as well and it still tends to,"},{"from":3471.2,"to":3472.71,"location":2,"content":"um, work pretty well."},{"from":3472.71,"to":3475.69,"location":2,"content":"So that's a good technique to know about."},{"from":3475.69,"to":3479.8,"location":2,"content":"Okay. Um, one last thing to learn about."},{"from":3479.8,"to":3482.07,"location":2,"content":"Um, there's a concept of,"},{"from":3482.07,"to":3487.01,"location":2,"content":"um, size one convolutions."},{"from":3487.01,"to":3491.24,"location":2,"content":"Um, and actually, I guess I really sort of, um,"},{"from":3491.24,"to":3494.68,"location":2,"content":"renamed it- I named this wrong because I wrote down"},{"from":3494.68,"to":3498.24,"location":2,"content":"one by one convolutions because that's the term you normally see."},{"from":3498.24,"to":3502.53,"location":2,"content":"But that's, um, the vision world where you have 2D convolutions."},{"from":3502.53,"to":3506.14,"location":2,"content":"So I guess I should have just called this one convolutions."},{"from":3506.14,"to":3508.89,"location":2,"content":"So you can have convolutions, um,"},{"from":3508.89,"to":3513.07,"location":2,"content":"with a kernel size of one and when you first see that,"},{"from":3513.07,"to":3517.84,"location":2,"content":"it seems like that makes no sense whatsoever because the whole idea"},{"from":3517.84,"to":3523.3,"location":2,"content":"of a convolution was I was taking this patch and calculating something from it."},{"from":3523.3,"to":3528.33,"location":2,"content":"If I'm not looking at any other words,"},{"from":3528.33,"to":3530.51,"location":2,"content":"surely I'm calculating nothing."},{"from":3530.51,"to":3534.97,"location":2,"content":"But what actually happens in the size one convolution,"},{"from":3534.97,"to":3539.16,"location":2,"content":"is if you have a number of channels that"},{"from":3539.16,"to":3543.85,"location":2,"content":"sort of in a previous layer if you'd calculated whatever it was,"},{"from":3543.85,"to":3546.61,"location":2,"content":"32 channels or something like that."},{"from":3546.61,"to":3551.07,"location":2,"content":"What the one by one convolution is doing is acting as"},{"from":3551.07,"to":3556.63,"location":2,"content":"a tiny little embedded fully-connected network over those channels."},{"from":3556.63,"to":3558.91,"location":2,"content":"And so you're sort of doing a"},{"from":3558.91,"to":3562.28,"location":2,"content":"position specific fully-connected network,"},{"from":3562.28,"to":3566.39,"location":2,"content":"um, in- for each row of your data."},{"from":3566.39,"to":3568.05,"location":2,"content":"And so you can do that,"},{"from":3568.05,"to":3569.59,"location":2,"content":"um, for various reasons."},{"from":3569.59,"to":3571.92,"location":2,"content":"You can do it because you want to map down from having"},{"from":3571.92,"to":3574.87,"location":2,"content":"a lot of channels to having fewer channels or"},{"from":3574.87,"to":3577.46,"location":2,"content":"you can do it just because you think another non-linearity"},{"from":3577.46,"to":3580.34,"location":2,"content":"will help and this is a really cheap way to do it."},{"from":3580.34,"to":3584.15,"location":2,"content":"Because the crucial thing to notice is that if you sort"},{"from":3584.15,"to":3587.99,"location":2,"content":"of put fully-connected layers over everything,"},{"from":3587.99,"to":3592.93,"location":2,"content":"they involve a lot of parameters whereas putting in these size"},{"from":3592.93,"to":3596.65,"location":2,"content":"one convolutions involve very few parameters"},{"from":3596.65,"to":3600.67,"location":2,"content":"because you're just doing it at the level of a single word."},{"from":3600.67,"to":3603.76,"location":2,"content":"Um, okay."},{"from":3603.76,"to":3608.59,"location":2,"content":"Um, two random things and then I'll go onto my complex model."},{"from":3608.59,"to":3610.54,"location":2,"content":"Um, this is just a sort of"},{"from":3610.54,"to":3613.66,"location":2,"content":"almost a bias- aside but it just shows"},{"from":3613.66,"to":3617.11,"location":2,"content":"something different that you could do and it's something that you could play with."},{"from":3617.11,"to":3620.07,"location":2,"content":"I mean, when we talked about machine translation,"},{"from":3620.07,"to":3624.5,"location":2,"content":"we talk about the SIC to SIC architecture that was introduced in"},{"from":3624.5,"to":3629.93,"location":2,"content":"2014 and has been very successful for machine translation."},{"from":3629.93,"to":3632.68,"location":2,"content":"But actually, the year before that came out,"},{"from":3632.68,"to":3634.86,"location":2,"content":"um, there was a paper, um,"},{"from":3634.86,"to":3641.26,"location":2,"content":"doing neural machine translation by Nal Kalchbrenner and Phil Blunsom in the UK."},{"from":3641.26,"to":3644.01,"location":2,"content":"And this sort of was actually essentially"},{"from":3644.01,"to":3648.84,"location":2,"content":"the first neural machine translation paper of the modern era."},{"from":3648.84,"to":3650.4,"location":2,"content":"If you dig back far enough,"},{"from":3650.4,"to":3652.13,"location":2,"content":"there are actually a couple of people that tried to use"},{"from":3652.13,"to":3654.14,"location":2,"content":"neural networks for machine translation"},{"from":3654.14,"to":3658.45,"location":2,"content":"in the '80s and '90s but this was sort of the first one that restarted it,"},{"from":3658.45,"to":3662.2,"location":2,"content":"and they didn't actually use a SIC to SIC architecture."},{"from":3662.2,"to":3665.69,"location":2,"content":"So what they used was for the encoder,"},{"from":3665.69,"to":3668.49,"location":2,"content":"they used the convolutional neural networks."},{"from":3668.49,"to":3673.43,"location":2,"content":"And so that they had a stack of convolutional neural networks that progressively shrunk"},{"from":3673.43,"to":3678.76,"location":2,"content":"down the input and then finally pulled it to get a sentence representation,"},{"from":3678.76,"to":3682.96,"location":2,"content":"and then they used a sequence model as the decoder."},{"from":3682.96,"to":3686.88,"location":2,"content":"Um, so, um, that's sort of something that you could"},{"from":3686.88,"to":3690.52,"location":2,"content":"try in some other applications that for encoders,"},{"from":3690.52,"to":3693.8,"location":2,"content":"it's really easy to use convolutional neural networks."},{"from":3693.8,"to":3699.18,"location":2,"content":"There has been work on using convolutional neural networks as decoders as well,"},{"from":3699.18,"to":3704.41,"location":2,"content":"though that's a little bit harder to get your brain around and isn't used nearly as much."},{"from":3704.41,"to":3710.96,"location":2,"content":"Then the second thing I want to mention because we'll turn to it in just a minute is so,"},{"from":3710.96,"to":3717.3,"location":2,"content":"so far we've done Convolutional models over words so that"},{"from":3717.3,"to":3720.89,"location":2,"content":"our kernels are effectively picking up"},{"from":3720.89,"to":3726.05,"location":2,"content":"these word n-gram units of two-word or three word sub-sequences."},{"from":3726.05,"to":3730.19,"location":2,"content":"And the idea that then developed fairly soon was well maybe"},{"from":3730.19,"to":3734.7,"location":2,"content":"it would also be useful to use convolutions over characters."},{"from":3734.7,"to":3737.11,"location":2,"content":"So, you could run a convolutional neural network"},{"from":3737.11,"to":3739.97,"location":2,"content":"over the characters of the word to try and,"},{"from":3739.97,"to":3742.64,"location":2,"content":"um, generate a word embedding, um,"},{"from":3742.64,"to":3745.76,"location":2,"content":"and this idea has been explored quite a lot, um,"},{"from":3745.76,"to":3748.51,"location":2,"content":"it's part of what you guys are gonna do for assignment"},{"from":3748.51,"to":3751.72,"location":2,"content":"five is build a character level ConvNet,"},{"from":3751.72,"to":3755.18,"location":2,"content":"um, for your improved machine translation system."},{"from":3755.18,"to":3760.25,"location":2,"content":"I'm not going to say sort of a huge amount about the foundations of this today, um,"},{"from":3760.25,"to":3764.27,"location":2,"content":"because Thursday's lecture is then talking about subword models"},{"from":3764.27,"to":3769.05,"location":2,"content":"and we'll go through all the details of different subword models."},{"from":3769.05,"to":3773.3,"location":2,"content":"But, I wanted to show you a con- a complex"},{"from":3773.3,"to":3778.01,"location":2,"content":"convolutional neural network which is also used for text classification."},{"from":3778.01,"to":3781.68,"location":2,"content":"So, essentially, the same task as Yoon Kim's model"},{"from":3781.68,"to":3786.23,"location":2,"content":"and this model actually is built on characters,"},{"from":3786.23,"to":3787.7,"location":2,"content":"it's not built on words."},{"from":3787.7,"to":3790.64,"location":2,"content":"So, we are at the foundation of it,"},{"from":3790.64,"to":3793.14,"location":2,"content":"um, having a word-like model."},{"from":3793.14,"to":3796.78,"location":2,"content":"Um, so, this is a paper from 2017,"},{"from":3796.78,"to":3801.35,"location":2,"content":"um, by, um, the four authors shown here, um,"},{"from":3801.35,"to":3804.17,"location":2,"content":"people working at Facebook AI Research,"},{"from":3804.17,"to":3807.64,"location":2,"content":"um, in France, um, and so,"},{"from":3807.64,"to":3810.32,"location":2,"content":"they kind of had an interesting hypothesis for"},{"from":3810.32,"to":3814.2,"location":2,"content":"this paper which was essentially to say, that, you know,"},{"from":3814.2,"to":3822.53,"location":2,"content":"by 2017 people who are using deep learning for vision were building really,"},{"from":3822.53,"to":3827.6,"location":2,"content":"really deep networks and fi- finding that they work much,"},{"from":3827.6,"to":3829.79,"location":2,"content":"much better for vision tasks."},{"from":3829.79,"to":3832.2,"location":2,"content":"So, essentially to some extend,"},{"from":3832.2,"to":3838.49,"location":2,"content":"the breakthrough was these guys that once these ideas that emerged,"},{"from":3838.49,"to":3844.45,"location":2,"content":"it then proved that it wasn't just that you could build a six layer or an eight layer,"},{"from":3844.45,"to":3847.58,"location":2,"content":"um, Convolutional Neural Network for vision tasks."},{"from":3847.58,"to":3849.2,"location":2,"content":"You could start building really,"},{"from":3849.2,"to":3854.27,"location":2,"content":"really deep networks for vision tasks which had tens or even hundreds of"},{"from":3854.27,"to":3861.21,"location":2,"content":"layers and that those models when trained on a lot of data proved to work even better."},{"from":3861.21,"to":3867.11,"location":2,"content":"So, um, if that's what's in your head and you then looked,"},{"from":3867.11,"to":3873.97,"location":2,"content":"look at what was and indeed is happening in natural language processing,"},{"from":3873.97,"to":3876.41,"location":2,"content":"the observation is, you know,"},{"from":3876.41,"to":3878.39,"location":2,"content":"these NLP people are kind of pathetic,"},{"from":3878.39,"to":3883.55,"location":2,"content":"they claim they're doing deep learning but they're still working with three layer LSTMs."},{"from":3883.55,"to":3886.47,"location":2,"content":"Surely, we can make some progress, um,"},{"from":3886.47,"to":3893.74,"location":2,"content":"by building really deep networks that kinda look like vision networks and using them,"},{"from":3893.74,"to":3897.03,"location":2,"content":"um, for natural language processing goals."},{"from":3897.03,"to":3901.41,"location":2,"content":"And so, that is precisely what they said about doing."},{"from":3901.41,"to":3908.93,"location":2,"content":"So, that they designed and built really deep network which sort of looks like a vision stack,"},{"from":3908.93,"to":3914.9,"location":2,"content":"um, as a convolutional neural network that is built over characters."},{"from":3914.9,"to":3920.66,"location":2,"content":"Um, so, I've got the picture of it here but sufficiently deep that it's fitting it on"},{"from":3920.66,"to":3923.39,"location":2,"content":"the slide and making it readable [LAUGHTER] is a little bit"},{"from":3923.39,"to":3926.15,"location":2,"content":"of a challenge but we can try and look at this."},{"from":3926.15,"to":3927.26,"location":2,"content":"So, at the bottom,"},{"from":3927.26,"to":3929.24,"location":2,"content":"we have the text, um,"},{"from":3929.24,"to":3933.97,"location":2,"content":"which is a sequence of characters and so, um,"},{"from":3933.97,"to":3936.98,"location":2,"content":"for the text, um, so,"},{"from":3936.98,"to":3940.64,"location":2,"content":"when people do vision object recognition on"},{"from":3940.64,"to":3944.93,"location":2,"content":"pictures normally all the pictures are made the same size."},{"from":3944.93,"to":3950.22,"location":2,"content":"Right. You make every picture 300 pixels by 300 pixels or something like that."},{"from":3950.22,"to":3953.38,"location":2,"content":"So, they do exactly the same for NLP, um,"},{"from":3953.38,"to":3955.49,"location":2,"content":"they have a size, um,"},{"from":3955.49,"to":3959.69,"location":2,"content":"for their document which is 1024 characters."},{"from":3959.69,"to":3963.71,"location":2,"content":"If it's longer than that they truncate it and keep the first part."},{"from":3963.71,"to":3966.47,"location":2,"content":"If it's shorter than that they pad it until it's of"},{"from":3966.47,"to":3971.32,"location":2,"content":"size 1024 and then they're gonna stick it into their stack."},{"from":3971.32,"to":3975.44,"location":2,"content":"So, the first part is that for each character,"},{"from":3975.44,"to":3978.2,"location":2,"content":"they're going to learn a character embedding now and"},{"from":3978.2,"to":3982.14,"location":2,"content":"their character embeddings are of dimensionality 16."},{"from":3982.14,"to":3989.54,"location":2,"content":"So, that the piece of text is now 16 by 1024, um, so,"},{"from":3989.54,"to":3993.77,"location":2,"content":"they're going to stick that through a convolutional layer where"},{"from":3993.77,"to":3998.21,"location":2,"content":"you've got kernel size of three and 64 output channels."},{"from":3998.21,"to":4004.15,"location":2,"content":"So you now have something that's 64 times of 1024 in size."},{"from":4004.15,"to":4007.9,"location":2,"content":"You now stick this through a convolutional block."},{"from":4007.9,"to":4012.09,"location":2,"content":"I'll explain the details of that convolutional block on the next slide but,"},{"from":4012.09,"to":4016.36,"location":2,"content":"you should be thinking of that ResNet picture I showed earlier where you"},{"from":4016.36,"to":4021.31,"location":2,"content":"can either be going through some convolutions or taking this optional shortcut."},{"from":4021.31,"to":4025.18,"location":2,"content":"Another ResNet, another residual block"},{"from":4025.18,"to":4028.76,"location":2,"content":"where you can be going through convolutions are an optional shortcut,"},{"from":4028.76,"to":4035.02,"location":2,"content":"um, they're then doing local pooling in the same way people typically do envision."},{"from":4035.02,"to":4037.99,"location":2,"content":"So, commonly what people do in vision systems"},{"from":4037.99,"to":4041.53,"location":2,"content":"is you are sort of shrinking the size of the images, um,"},{"from":4041.53,"to":4045.82,"location":2,"content":"by doing pooling that halves the dimensions in each direction."},{"from":4045.82,"to":4047.02,"location":2,"content":"But, at the same time,"},{"from":4047.02,"to":4049.01,"location":2,"content":"you do that in your neural network,"},{"from":4049.01,"to":4051.72,"location":2,"content":"you expand the number of channels,"},{"from":4051.72,"to":4054.13,"location":2,"content":"and so you make it deeper in terms of the number of"},{"from":4054.13,"to":4058.11,"location":2,"content":"channels at the same time as you make it smaller in the x,"},{"from":4058.11,"to":4059.71,"location":2,"content":"y size of the image."},{"from":4059.71,"to":4064.12,"location":2,"content":"So, they do exactly the same apart from these one-dimensional convolutions."},{"from":4064.12,"to":4069.76,"location":2,"content":"So, before we had 64 channels in our 1024 character,"},{"from":4069.76,"to":4074.43,"location":2,"content":"um, embedding, um, document."},{"from":4074.43,"to":4077.11,"location":2,"content":"So, now we pool it, um, so,"},{"from":4077.11,"to":4083.61,"location":2,"content":"we're going to have 512 positions which are sort of like pairs of characters,"},{"from":4083.61,"to":4086.44,"location":2,"content":"um, but we now have 128 channels"},{"from":4086.44,"to":4089.38,"location":2,"content":"and then they kind of repeat that over and over again, right?"},{"from":4089.38,"to":4091.69,"location":2,"content":"So, there are two more convolutional blocks which I'll"},{"from":4091.69,"to":4094.28,"location":2,"content":"explain more but they're sort of residual blocks."},{"from":4094.28,"to":4097.96,"location":2,"content":"They pool it again and they do exactly the same thing."},{"from":4097.96,"to":4101.31,"location":2,"content":"So, now there are 256, um,"},{"from":4101.31,"to":4106.9,"location":2,"content":"positions which are like four character blocks and they have 256 channels,"},{"from":4106.9,"to":4111.46,"location":2,"content":"um, I can't point high enough but they repeat that again and they pool again."},{"from":4111.46,"to":4113.59,"location":2,"content":"So, now they've got, um,"},{"from":4113.59,"to":4116.71,"location":2,"content":"128 positions which are about eight characters"},{"from":4116.71,"to":4120.77,"location":2,"content":"each and they have 512 channels representing that."},{"from":4120.77,"to":4125.08,"location":2,"content":"They pool again, they have convolutional blocks again, um,"},{"from":4125.08,"to":4127.57,"location":2,"content":"then lo and behold because I said that even the"},{"from":4127.57,"to":4130.06,"location":2,"content":"weird ideas are going to turn up, right up there,"},{"from":4130.06,"to":4135.32,"location":2,"content":"they're doing k max pooling and they're keeping the eight strongest values,"},{"from":4135.32,"to":4137.29,"location":2,"content":"um, in each channel."},{"from":4137.29,"to":4139.3,"location":2,"content":"Um, and so at that point,"},{"from":4139.3,"to":4145.19,"location":2,"content":"they've got something of size 512 by eight, um, so,"},{"from":4145.19,"to":4148.51,"location":2,"content":"sort of like eight of the eight character sequences"},{"from":4148.51,"to":4151.7,"location":2,"content":"have been deemed important to the classification and they're"},{"from":4151.7,"to":4155.45,"location":2,"content":"kept but they sort per channel and there are 512 of them"},{"from":4155.45,"to":4159.48,"location":2,"content":"you're then putting that through three fully connected layers."},{"from":4159.48,"to":4162.19,"location":2,"content":"So, typically vision systems at the top"},{"from":4162.19,"to":4165.35,"location":2,"content":"have a couple of fully connected layers at the end,"},{"from":4165.35,"to":4168.06,"location":2,"content":"um, and the very last one of those,"},{"from":4168.06,"to":4171.84,"location":2,"content":"is effectively sort of feeding into your Softmax."},{"from":4171.84,"to":4176.08,"location":2,"content":"So, it's size 2,048 times the number of"},{"from":4176.08,"to":4181.33,"location":2,"content":"classes which might just be positive negative two class unlike the topical classes."},{"from":4181.33,"to":4184,"location":2,"content":"Um, so, yeah, so it's essentially like"},{"from":4184,"to":4187.18,"location":2,"content":"a vision stack but they're going to use it for language."},{"from":4187.18,"to":4188.89,"location":2,"content":"Um, okay."},{"from":4188.89,"to":4192.34,"location":2,"content":"So, the bit that I hand quite explained was"},{"from":4192.34,"to":4197.52,"location":2,"content":"these convolutional blocks but it sort of looks like the picture that we had before or,"},{"from":4197.52,"to":4199.98,"location":2,"content":"um, departments slightly more complicated."},{"from":4199.98,"to":4202.42,"location":2,"content":"So you're doing, um,"},{"from":4202.42,"to":4205.84,"location":2,"content":"a convolutional block of size three"},{"from":4205.84,"to":4210.43,"location":2,"content":"convolutions some number of channels depending on where you are in the sequence."},{"from":4210.43,"to":4213.49,"location":2,"content":"You're then putting it through a batch norm as we just"},{"from":4213.49,"to":4217.07,"location":2,"content":"talked about putting it through a ReLu non-linearity,"},{"from":4217.07,"to":4221.32,"location":2,"content":"repeating all those three things again or remember there"},{"from":4221.32,"to":4225.55,"location":2,"content":"was this sort of skipped connection that went right around the outside of this block."},{"from":4225.55,"to":4231.19,"location":2,"content":"And so this is sort of a residual style block, um, so,"},{"from":4231.19,"to":4234.55,"location":2,"content":"that's the kind of complex architecture you can put together and"},{"from":4234.55,"to":4238.68,"location":2,"content":"try in your final projects if you dare in PyTorch."},{"from":4238.68,"to":4242.77,"location":2,"content":"Um, yeah, um, so,"},{"from":4242.77,"to":4246.09,"location":2,"content":"for experiments so- so one of"},{"from":4246.09,"to":4252.57,"location":2,"content":"the things that they were interested in and wanted to make a point of is well some"},{"from":4252.57,"to":4255.67,"location":2,"content":"of these traditional sentence and"},{"from":4255.67,"to":4258.97,"location":2,"content":"text classification datasets have been used in other papers"},{"from":4258.97,"to":4262.47,"location":2,"content":"like Yoon Kim's paper are effectively quite small."},{"from":4262.47,"to":4270.55,"location":2,"content":"So, something like that Rotten Tomatoes dataset is actually only 10,000 examples, 5,000,"},{"from":4270.55,"to":4273.55,"location":2,"content":"positive 5,000 negative and they sort of have"},{"from":4273.55,"to":4277.18,"location":2,"content":"the idea that just like ImageNet was needed for"},{"from":4277.18,"to":4280.44,"location":2,"content":"deep learning models to really show their worth and vision"},{"from":4280.44,"to":4284.15,"location":2,"content":"that probably does show the value of a huge model like that."},{"from":4284.15,"to":4288.07,"location":2,"content":"Um, you need to have really big datasets."},{"from":4288.07,"to":4289.85,"location":2,"content":"So, they get some much bigger,"},{"from":4289.85,"to":4292,"location":2,"content":"um, text classification datasets."},{"from":4292,"to":4296.06,"location":2,"content":"So, here's an Amazon review positive-negative dataset, um,"},{"from":4296.06,"to":4299.5,"location":2,"content":"with which they have sort of 3.6 million documents,"},{"from":4299.5,"to":4303.03,"location":2,"content":"um, Yelp reviews 650,000 documents."},{"from":4303.03,"to":4305.1,"location":2,"content":"So much bigger datasets,"},{"from":4305.1,"to":4308.23,"location":2,"content":"um, and here are their experiments."},{"from":4308.23,"to":4310.93,"location":2,"content":"Okay. So, the numbers at the top, uh,"},{"from":4310.93,"to":4315.94,"location":2,"content":"for the different datasets of the best previous result printed in the literature,"},{"from":4315.94,"to":4318.64,"location":2,"content":"and then if you read the, um,"},{"from":4318.64,"to":4323.2,"location":2,"content":"footnotes, um, there are a few things that they want to sort of star."},{"from":4323.2,"to":4327.04,"location":2,"content":"So, the ones that have a star next to them use"},{"from":4327.04,"to":4333.23,"location":2,"content":"an external thesaurus which they don't use. [NOISE]"},{"from":4333.23,"to":4335.64,"location":2,"content":"And the Yang method, um,"},{"from":4335.64,"to":4338.61,"location":2,"content":"use some special techniques as well that I cut off."},{"from":4338.61,"to":4341.58,"location":2,"content":"Um, and the other thing to mention is these numbers,"},{"from":4341.58,"to":4344.18,"location":2,"content":"they're error rates, so low is good."},{"from":4344.18,"to":4346.41,"location":2,"content":"Um, so the lower you get them, the better."},{"from":4346.41,"to":4350.94,"location":2,"content":"And so then these are all of their results."},{"from":4350.94,"to":4354.77,"location":2,"content":"Um, and so what can you get out of these results?"},{"from":4354.77,"to":4359.55,"location":2,"content":"Um, well, the first thing that you can notice is basically with these results,"},{"from":4359.55,"to":4362.1,"location":2,"content":"the deeper networks are working better, right?"},{"from":4362.1,"to":4364.85,"location":2,"content":"So, the one I showed you,"},{"from":4364.85,"to":4368.49,"location":2,"content":"uh, well, no, I think the one that I have the picture of this isn't the full thing."},{"from":4368.49,"to":4372.72,"location":2,"content":"Um, but they have ones with depth 9, 17,"},{"from":4372.72,"to":4376.68,"location":2,"content":"and 29 in terms of the number of convolutional layers,"},{"from":4376.68,"to":4381.15,"location":2,"content":"and the deepest one is always the one that's working best."},{"from":4381.15,"to":4384.26,"location":2,"content":"So, that's a proof of deep networks."},{"from":4384.26,"to":4387.57,"location":2,"content":"Um, that didn't keep on working, um,"},{"from":4387.57,"to":4390.69,"location":2,"content":"so an interesting footnote here is,"},{"from":4390.69,"to":4391.94,"location":2,"content":"um, I guess they thought,"},{"from":4391.94,"to":4393.23,"location":2,"content":"oh, this is cool."},{"from":4393.23,"to":4399.31,"location":2,"content":"Why don't we try an even deeper one that has 47 layers and see how well that works?"},{"from":4399.31,"to":4403.64,"location":2,"content":"And, I mean, the results were sort of interesting for that."},{"from":4403.64,"to":4406.13,"location":2,"content":"So, for the 47 layer one,"},{"from":4406.13,"to":4408.85,"location":2,"content":"it worked a fraction worse than this one."},{"from":4408.85,"to":4412.05,"location":2,"content":"Um, so in one sense you,"},{"from":4412.05,"to":4417.9,"location":2,"content":"they showed the result of sort of residual layers work really well."},{"from":4417.9,"to":4420.7,"location":2,"content":"So, they did an experiment of let's try to train"},{"from":4420.7,"to":4425.32,"location":2,"content":"a 47-layer network without using residual connections."},{"from":4425.32,"to":4427.45,"location":2,"content":"And, well, it was a lot worse."},{"from":4427.45,"to":4429.87,"location":2,"content":"The numbers went down about two percent."},{"from":4429.87,"to":4432.82,"location":2,"content":"And they trained one with residual connections,"},{"from":4432.82,"to":4438.87,"location":2,"content":"and the fact of the matter is the numbers were just a teeny weeny bit worse."},{"from":4438.87,"to":4442.48,"location":2,"content":"They were sort of 0.1 of a percent worse."},{"from":4442.48,"to":4445.52,"location":2,"content":"So, you know, they sort of work just about as well."},{"from":4445.52,"to":4450.3,"location":2,"content":"But, nevertheless, that's kind of different to the situation in vision,"},{"from":4450.3,"to":4455.15,"location":2,"content":"because for the sort of residual networks that people are using in vision,"},{"from":4455.15,"to":4459.99,"location":2,"content":"this is sort of like the very minimum depth that people use."},{"from":4459.99,"to":4463.48,"location":2,"content":"So, if you're using residual networks in vision typically,"},{"from":4463.48,"to":4465.91,"location":2,"content":"you might use ResNet-34."},{"from":4465.91,"to":4469.22,"location":2,"content":"If you're really short on memory and want to have a small model,"},{"from":4469.22,"to":4472.98,"location":2,"content":"but you just know you'd get better results if you used ResNet-50,"},{"from":4472.98,"to":4476.73,"location":2,"content":"and in fact, if you used ResNet-101 it'd work even better again."},{"from":4476.73,"to":4479.63,"location":2,"content":"Um, and so that somehow, you know,"},{"from":4479.63,"to":4481.41,"location":2,"content":"whether it's got to do with the different nature of"},{"from":4481.41,"to":4484.35,"location":2,"content":"language or the amounts of data or something,"},{"from":4484.35,"to":4487.91,"location":2,"content":"you haven't yet gone to the same depth that you can in vision."},{"from":4487.91,"to":4490.62,"location":2,"content":"Um, but other results, um,"},{"from":4490.62,"to":4494.19,"location":2,"content":"so the other thing they're comparing here is that they're comparing"},{"from":4494.19,"to":4499.24,"location":2,"content":"three different ways of sort of stringing things down."},{"from":4499.24,"to":4502.95,"location":2,"content":"So, you could be using, um,"},{"from":4502.95,"to":4506.72,"location":2,"content":"the stride in the Convolution,"},{"from":4506.72,"to":4509.74,"location":2,"content":"you can be using local MaxPooling,"},{"from":4509.74,"to":4512.81,"location":2,"content":"and you could be using KMaxPooling."},{"from":4512.81,"to":4514.35,"location":2,"content":"Um, and they're general,"},{"from":4514.35,"to":4516.94,"location":2,"content":"they're slightly different numbers as you can see."},{"from":4516.94,"to":4519.99,"location":2,"content":"Each one, um, wins and one, uh,"},{"from":4519.99,"to":4523.89,"location":2,"content":"at least one of these datasets or actually at least two of these datasets."},{"from":4523.89,"to":4527.43,"location":2,"content":"But not only does MaxPooling win for four of the datasets,"},{"from":4527.43,"to":4529.89,"location":2,"content":"if you sort of look at the numbers,"},{"from":4529.89,"to":4532.24,"location":2,"content":"MaxPooling always does pretty well."},{"from":4532.24,"to":4534.49,"location":2,"content":"Because MaxPooling does pretty well here,"},{"from":4534.49,"to":4538.14,"location":2,"content":"whereas the convolutional stride works badly,"},{"from":4538.14,"to":4541.6,"location":2,"content":"and over here MaxPooling works pretty well,"},{"from":4541.6,"to":4545.69,"location":2,"content":"and the, um, KMaxPooling works kind of badly."},{"from":4545.69,"to":4550.89,"location":2,"content":"So, their recommendation at the end of the day is you should always use, um,"},{"from":4550.89,"to":4553.68,"location":2,"content":"just MaxPooling of a simple kind,"},{"from":4553.68,"to":4555.39,"location":2,"content":"that that seems to be fine,"},{"from":4555.39,"to":4557.34,"location":2,"content":"um, and nothing else."},{"from":4557.34,"to":4561.31,"location":2,"content":"Um, it's actually worth the trouble of thinking about doing."},{"from":4561.31,"to":4570.54,"location":2,"content":"Okay. Um, was there any other conclusions I wanted to say?"},{"from":4570.54,"to":4573.28,"location":2,"content":"Okay. Um, I think that was most of that."},{"from":4573.28,"to":4577.44,"location":2,"content":"I guess their overall message is you can build super good, um,"},{"from":4577.44,"to":4580.47,"location":2,"content":"text classification systems using ConvNets,"},{"from":4580.47,"to":4582.63,"location":2,"content":"and you should take away that message."},{"from":4582.63,"to":4586.17,"location":2,"content":"Okay. So, there are just a couple of minutes left."},{"from":4586.17,"to":4590.15,"location":2,"content":"There was sort of one other thing that I wanted to mention,"},{"from":4590.15,"to":4593.51,"location":2,"content":"but I think I'll just sort of mention it very quickly,"},{"from":4593.51,"to":4596.51,"location":2,"content":"and you can look in more detail if you want to."},{"from":4596.51,"to":4598.78,"location":2,"content":"So, we sort of have this situation"},{"from":4598.78,"to":4604.06,"location":2,"content":"that re- recurrent neural networks are a very standard building block for NLP,"},{"from":4604.06,"to":4609.4,"location":2,"content":"but they have this big problem that they just don't parallelize well."},{"from":4609.4,"to":4613.8,"location":2,"content":"And the way we get fast computation deep learning is we find"},{"from":4613.8,"to":4618.18,"location":2,"content":"things that parallelize well so that we can stick them on GPUs."},{"from":4618.18,"to":4625.43,"location":2,"content":"GPUs only are fast if they can be simultaneously doing the same computation many times,"},{"from":4625.43,"to":4628.44,"location":2,"content":"which is sort of trivial for a convolutional neural network,"},{"from":4628.44,"to":4633.23,"location":2,"content":"because precisely, you're doing the same comput- computation every position."},{"from":4633.23,"to":4637.74,"location":2,"content":"But that's not what's happening in the recurrent neural network because you have to"},{"from":4637.74,"to":4639.99,"location":2,"content":"work out the value of position one"},{"from":4639.99,"to":4642.93,"location":2,"content":"before you can start to calculate the value of position two,"},{"from":4642.93,"to":4646.32,"location":2,"content":"which is used for the value of position three."},{"from":4646.32,"to":4648.98,"location":2,"content":"Um, so this was a piece of work, um,"},{"from":4648.98,"to":4653.03,"location":2,"content":"done by sometimes CS224N co-instructor"},{"from":4653.03,"to":4657.62,"location":2,"content":"Richard Socher and some of his people at Salesforce Research"},{"from":4657.62,"to":4660.11,"location":2,"content":"on saying, how can we get the best of both worlds?"},{"from":4660.11,"to":4663.48,"location":2,"content":"How can we get something that's kind of like a"},{"from":4663.48,"to":4669.65,"location":2,"content":"recurrent neural network, but doesn't have the bad computational properties?"},{"from":4669.65,"to":4673.16,"location":2,"content":"And so the idea that they had was, well,"},{"from":4673.16,"to":4680.55,"location":2,"content":"rather than doing the standard LSTM style thing where you're calculating, you know,"},{"from":4680.55,"to":4687.09,"location":2,"content":"an updated candidate value and your gates in terms of the preceding time slice,"},{"from":4687.09,"to":4693.51,"location":2,"content":"maybe what instead we could do is we could stick a relation between time"},{"from":4693.51,"to":4700.15,"location":2,"content":"minus 1 and time into the MaxPooling layer of a convolutional neural network."},{"from":4700.15,"to":4706.26,"location":2,"content":"So, we're sort of calculating a candidate and a forget gate and an output gate."},{"from":4706.26,"to":4710.7,"location":2,"content":"But these, these candidate and the, um,"},{"from":4710.7,"to":4718.5,"location":2,"content":"gated values are done inside the pooling layer via compute,"},{"from":4718.5,"to":4724.35,"location":2,"content":"um, via, um, uh, uh, convolutional operation."},{"from":4724.35,"to":4726.15,"location":2,"content":"So, it sort of get,"},{"from":4726.15,"to":4727.65,"location":2,"content":"it doesn't, it, you know,"},{"from":4727.65,"to":4733.06,"location":2,"content":"if there's no free lunch you can't get true recurrence and not pay the penalty."},{"from":4733.06,"to":4736.76,"location":2,"content":"This is giving you sort of a pseudo-recurrence because you are"},{"from":4736.76,"to":4742.24,"location":2,"content":"modeling an association between adjacent elements at each time slice,"},{"from":4742.24,"to":4746.31,"location":2,"content":"but it's sort of just worked out locally rather than being carried forward,"},{"from":4746.31,"to":4748.2,"location":2,"content":"um, in one layer."},{"from":4748.2,"to":4750.24,"location":2,"content":"But sort of what they found is,"},{"from":4750.24,"to":4754.32,"location":2,"content":"if you made your networks deeper using this idea,"},{"from":4754.32,"to":4755.97,"location":2,"content":"well then, you sort of start to, again,"},{"from":4755.97,"to":4758.01,"location":2,"content":"expand your window of influence."},{"from":4758.01,"to":4762.09,"location":2,"content":"So, you got a certain amount of information being carried forward."},{"from":4762.09,"to":4765.33,"location":2,"content":"Um, so, their conclusions was that you could sort of"},{"from":4765.33,"to":4768.87,"location":2,"content":"build these kind of models and get them to work,"},{"from":4768.87,"to":4772.05,"location":2,"content":"you know, not necessarily better actually on this slide,"},{"from":4772.05,"to":4773.63,"location":2,"content":"um, it says often better."},{"from":4773.63,"to":4777.54,"location":2,"content":"Um, you can get them to work kind of as well as an LSTM does,"},{"from":4777.54,"to":4781.65,"location":2,"content":"but you could get them to work much faster because you're avoiding"},{"from":4781.65,"to":4786.56,"location":2,"content":"the standard recurrent operation and keeping it as something that you can parallelize,"},{"from":4786.56,"to":4789.94,"location":2,"content":"um, in the MaxPooling operations."},{"from":4789.94,"to":4793.03,"location":2,"content":"Um, yes, so that was a kind of"},{"from":4793.03,"to":4797.25,"location":2,"content":"an interesting alternative way of sort of trying to get some of the benefits."},{"from":4797.25,"to":4801.82,"location":2,"content":"I think long-term this isn't the idea that's going to end up winning out."},{"from":4801.82,"to":4805.74,"location":2,"content":"And so next week we're going to talk about transformer networks,"},{"from":4805.74,"to":4809.65,"location":2,"content":"which actually seems to be the idea that's gained the most steam at the moment."},{"from":4809.65,"to":4812.83,"location":2,"content":"Okay. I'll stop there for today. Thanks a lot."}]}